网络协议
    基础概念
        网络协议规定了数据是如何从一个设备传递到另一个设备的
        每一种网络协议,它的应用场景都不一样
            也不是说非得一个领域要用一个协议,只是说用这个协议好一点,事半功倍
        C/C++跨平台原理
            会根据不同的系统,将源文件编译成不同的格式
                windows平台就编译成PE格式
                MacOS就编译成Mach-O格式
                Linux就编译成 ELF格式
                不同的平台就需要编译多次
            使用平台相关的编译器生成对应平台的可执行文件,编译多次生成不同的可执行文件   
        Java跨平台
            编译一次生成class文件,由对应平台的JVM翻译成对应的机器码指令进行执行
        网络协议约束了网络之间传输的数据格式,一种规范,国际标准组织进行规范,防止标准和规范不一样,网络间显得太混乱
            1985年制定网络互连模型OSI
        OSI七层模型
            物理层---数据链路层---网络层---传输层---会话层---表示层---应用层
        四层模型(实际应用)---TCP/IP协议
            实际应用过程中应用到的
            网络接口层---网络层---传输层---应用层
        学习研究
            物理层---数据链路层---网络层---传输层---应用层
        传输过程
            客户端拿到要发送的数据,然后根据层级一层一层的包装,然后发送给服务器,服务器拿到包装过的数据之后,然后再从下面一层一层的解析最终拿到客户端的原始数据
    通信基础
        首先先要获取对方的ip地址,再拿到目标网卡(MAC)地址,看如果这个目标网卡地址是不是当前机器,如果不是的话就会将数据扔掉,是的话,就会将数据传递给上一层进行处理
        源IP地址,目标IP地址,源MAC地址,目标MAC地址
        连接方式
            同一网段
                同一广播域
                网线直连
                    网段不一样,不能直接通(ping不了),这个时候就需要使用路由器
                    ping走的就是ICMP协议
                    
                    第一次ping的时候就可以获取到mac地址
                    ARP
                        用于发送广播,获取目标的MAC地址
                        获取mac地址是通过ARP广播协议,跟我连着的,能通的,都会发送出去,在同一个网段中传播,不同网段之间是隔绝广播的,发广播的目的就是获取对应ip的"网卡"MAC地址

                        通过ARP协议进行广播的时候,目标MAC地址会变成FFFF.FFFF.FFFF,所以只要发现目标MAC地址是FFFF.FFFF.FFFF的,就是个广播
                        只有通过ARP拿到目的MAC地址之后,ICMP才可以正常工作,要不然,连人家MAC地址都不知道,怎么搞?

                        ARP是有缓存的(保存到计算机中)

                    两台电脑之间直接通信的话,需要使用交叉线,不能使用直通线

                    同种设备交叉线,不同设备直连线
                同轴电缆(被淘汰)---一个比较大的冲突域
                    如果多个设备之间需要直连通信,那么需要使用同轴电缆
                    终结电阻+T型连接器
                        同轴电缆的两端有终结电阻,然后存在T型连接器,一个T型连接器连接一个设备
                    采用半双工通信
                        设备之间有一条通道,但是只能单方向传输,A给B传数据的时候,B就不能给A传,B给A传的时候,A就不能给B传,"同一时间只能允许单方向传输"
                        效率不高
                    存在的问题
                        1. 半双工通信导致效率不高
                            因为采用半双工通信,同一时间只能单方向通信,导致效率不是很高
                        2. 信号扩散到处扩散
                            设备往外发的时候,通过T型连接器发的时候会往左右两端进行扩散,没智商
                            1,2,3,4,5 5台机器,假如3号机器往外给5号发送数据,那么通过T型连接器会向左右都进行传播,那么 1,2,4,5 都会接收到信号,而 1,2,4 接收到数据之后呢,由于目标MAC地址对不上,所以会将数据丢失,实际上也是可以实现5精确接受并处理了,但是很deeer

                        3. 信号反弹
                            也就是为什么要有终结电阻呢?
                            用于抵消信号,假如3往外发,如果碰到某个东西之后,那可能会导致信号反弹,这就很麻烦,所以走到电阻那里就会将使得信号消失
                        4. 比较容易发生冲突(同一段链路)
                            因为采用半双工通信,在某一个时刻某一段链路上只能允许单个通讯
                            而如果有一台机器往外发送信息的时候,会先检测发现这段链路上是否有人在通信,如果有,那么他就会等一个随机时间,然后再进行发送

                            冲突域
                        5. 不安全
                            因为数据直接发出去了,发给每一台可以到达的机器,即便不是目标机器,也会发过去,那如果人家在机器上装一些抓包工具,那数据就不安全了
                        6. 中间如果断掉了,整个都瘫了
                            因为中间某个地方断了之后,其他地方去发,那个终结电阻就没了,没了之后信号就可能会反弹,那GG
                集线器---相当于Hub
                    概述
                        可以连接很多个设备,看有多少个接口
                        如果A集线器只有两三个接口,那如果这个时候还想让更多的设备进行通信怎么办? 那么就A再多接集线器就行
                        
                    也是采用半双工通信
                    缺点
                        1. 半双工通信,效率不高
                        2. 容易冲突
                            因为采用半双工通信
                        3. 不安全
                        4. 跟同轴电缆一样,没有智商(收到信息过来就发出去了)
                            也是一个设备往外发,会向集线器内所有设备都无脑发送,有多少连接发多少
                    但是不会出现某一段断掉了,然后整个都瘫了

                    集线器不会存储arp的MAC地址,只有计算机有缓存(会记录MAC地址)
                    arp -a 可以看到已经保存的MAC地址等信息
                
                网桥(Bridge)
                    集线器存在的问题
                        如果集线器连接了很多很多设备,比如说一千多台,那发送数据的时候会发给1k多台,ARP广播获取MAC地址的时候全部发送这个都可以理解,但是通过ARP拿到MAC地址之后传输数据,还是要发给一千多台设备... 这不就很deer吗,会很长时间占用带宽和链路

                        也就是设备越多的话,效率越低

                        网桥就是解决这个问题的
                    概述
                        网桥连接起来的计算机都还是处于同一个网段

                        能够通过自学习得知每个接口那侧的MAC地址
                            两个接口嘛
                            相当于有一个MAC地址表
                                假如A往B进行ARP广播,那么进行ARP的时候,传过去传过来的这个过程中获取到目标MAC地址之后,会存起来
                                接口        MAC地址
                                左侧接口    A的MAC地址 
                                右侧接口    B的MAC地址

                            当ARP发完,然后获取到对应的目标MAC地址之后,那么下一次真正准备发送数据的时候,网桥已经记录了目标MAC地址,比如说目标MAC地址就在左侧接口,好,那么这个时候数据就不会再往右侧接口的设备进行发送,这样呢就某种程度上避免了上面说的集线器存在的问题

                            这样就可以过滤掉一部分无效的请求发送,然后呢因为采用半双工通信,所以效率某种意义上提高,带宽/链路占用降低

                            ARP广播之后,B在回复ARP的时候,信号也不会通过网桥传递给右侧冲突域,因为第一次A的MAC地址已经记录到了网桥中,而此时B进行回复,目标MAC地址就是A的MAC地址,所以通过网桥时,网桥就会知道,你这个目标MAC啊就在我的左边,那肯定就不会再将信号传递给右侧冲突域了
                        作用
                            可以通过自学习得知每个接口的MAC地址
                            可以隔绝/拆分冲突域
                                比如两个冲突域之间用网桥连接,那么如果左边只是想跟左边进行通信,那么按照传统集线器的方式,这两就是一个冲突域,那也会占用右侧的带宽/链路,那么如果用网桥将两个冲突域进行连接,左侧跟左侧通信,就只会只占用左侧的带宽/链路,对右侧没有影响

                                那当然,如果左侧和右侧通信,那肯定还是要全部占用
                        缺点
                            网桥只有两个接口
                                也就是说,网桥只能隔绝两个冲突域,而在同一个冲突域中的设备也会冲突

                                解决冲突不彻底
                交换机(Switch)
                    概述
                        相当于接口更多的升级版本的网桥

                        可以说是局域网(不跨网段的最终方案,如果要跨网段就需要用到路由器)

                        网桥和集线器(Hub)没有ip和mac地址,就相当于是个高级一点的网线了

                        交换机有ip吗?
                            二层交换机没有ip
                            三层交换机有ip层
                    优点
                        比网桥更智能
                        全双工通信
                            同一时间可以双方向传输
                        比集线器安全
                            因为毕竟相当于是精准发送了,不会发送给无效的设备,那么就可以防止恶意抓包啊之类的
                            同轴电缆啊,集线器啊,会存在发给不必要的机器,人家只是默认看到不是发给我的然后就丢掉,但是这个是可以装抓包工具的
                        可以隔绝更多的冲突域,接口更多嘛
                    特点
                        有很多个接口,计算机直接去接上这个交换机,那么在一次广播之后,基本上可以拿到所有的MAC地址,然后呢接口和MAC存储起来,那么下一次设备之间进行通信的时候,那就直接可以精准发送

                        A--->B
                        第一次ARP的时候,肯定还是会将信号传递给所有设备,只不过其他设备会将数据丢掉,因为看到ip不是自己,那么在B设备进行回复的时候,这个时候实际上交换机已经记录了A的MAC,所以此时只会将信号传递给A,不会去走其他接口,而且此时会记录B的MAC,
                        那么在ARP之后正式发送给数据到B的时候,就直接走对应的接口,不会向其他接口进行发送
                    如果全球所有的设备都用交换机连接会怎么样?
                        交换机只能连接同一个网段的设备,那么说明全球计算机都在同一个网段,那ip肯定不够用奥
                        那一发ARP广播,那么同一个网段的都能收到,全球就都能收到了奥,那每次通信都要全球到处发广播???deer
                        
                        这就是出现广播风暴

                        所以这个时候就需要路由器
                总结
                    网线直连,同轴电缆,集线器,网桥,交换机连接的设备必须在同一网段+同一广播域

                    这些设备基本都不需要ip地址,就是用来转发数据的

            光猫是调制解调器
                就是比如电信号变光信号,涉及到信号之间的转换
            不同网段
                路由器
                    概述
                        用来连接不同网段的设备
                        
                        家用路由器里面内置了交换机的功能,看起来电脑只连接了路由器,但是本质还是电脑先连接了交换机,再连接了路由器
                    特点
                        1. 可以在不同网段之间转发数据
                            如果不同的网段的两台机器,中间放一个交换机进行连接,他们是ping不通的,而如果放台路由器,是可以ping通的
                        2. 可以"隔绝广播域"
                        不要在同网段的设备之间连一个路由器啊
                    
                    主机发送数据之前,首先会判断目标主机的IP地址跟它是否在同一个网段
                        如果在同一网段
                            通过ARP协议进行广播,通过交换机/集线器/网桥等传输数据
                        如果不在同一个网段
                            不同网段就不会发送ARP,而是通过路由器转发数据
                            怎么通过路由器转发数据呢?
                                网关gateway
                                路由器提供网关,如果想在不同网段之间传输数据,就必须通过网关

                                路由器上有很多网关,通过网关,就可以确定到要发送到哪个网段
                                那么这个时候就"要保证网关和对应的设备在同一个网段/广播域",比如说路由器左侧的网关IP地址,那肯定就要和左侧的设备处于同一个网段,要不然数据到不了网关(不同网段不能直接通信)

                                网关的ip呢一般配当前网段的第一个ip   eg:192.168.3.1

                                如果路由器收到了ARP,他就会直接扔掉,因为是隔绝广播域的,你连接的就是不同的网段,中间被交换机隔绝了,那左边的ARP肯定是不能广播到右边的,右边的广播肯定也发送不到左边去
                            路由器配置了网关之后,"计算机也需要配置相应的默认网关",要不然计算机肯定不知道网关的ip啊
                    网关的作用
                        帮助跨网段传输
                        网关口连接的就是对应的网段,比如PC啊,交换机啊...
                    跨网段传输的过程
                        1. 刚开始第一次也是要发送ARP广播
                            虽然说通过路由器跨网段传输是会隔绝广播域的,但是他要通过路由器上的网关将数据发送出去,所以这一次他就要去获取路由器上网关的MAC地址,所以还是会发送ARP广播,目的是"获取网关的MAC地址"
                        2. 网关回复ARP
                            那么路由器上的网关收到信号之后,就会将当前的MAC地址通过ARP返回回去,回去的时候假如说经过了交换机,那就直接回到发送的设备上(交换机对ip和mac有记录)
                        3. 到此,拿到了网关的MAC,才会真正的将数据发送到网关,网关一看,诶不是同一个网段的,再转发给对应的网关
                        4. 对应网关发送ARP
                            因为毕竟他也不知道目的ip地址的MAC地址,所以也是要ARP去进行获取,先判断是否是同一个网段,如果不是同一个网段,也是获取这个网段的网关mac,方便后续发送
                        5. 拿到对应MAC之后,网关就会将数据发送过去
                        6. 目的设备处理完之后,就会按照原路将数据回传

                        总的来讲呢,跨网段传输,第一次的话,就是先ARP拿到当前网关的MAC地址,因为不知道目标ip的mac是多少,但是可以通过ARP广播获取到当前网段的网关mac,网关呢就可以帮我们把数据传出去,然后拿到网关的MAC之后,就可以将数据传给网关,网关在路由器上,它拿到这个要传送的目的ip之后,会转给相应网段的网关B,那这个网关B他第一次也不知道目的ip的MAC是多少啊,所以在同一个网段内也是要通过ARP去广播,然后呢拿到目的ip的MAC之后,进行数据发送,发送之后然后目的方传回

                    路由器可以有多个网关口,每一个网关都有自己的IP和MAC地址

                    如果是同一个网段的两台设备之间搞一个路由器,那由于在同一个网段,实际上他就不会去找网关了


        MAC地址
            概述
                每一个网卡都有6字节(48bit)十六进制的MAC地址(Media Access Control Address) 
                    一个十六进制 4bit 
                组织唯一标识符+网络接口标识符
                40-55-82       0A-8C-6D
            特点
                6个字节十六进制组成
                全球唯一
                    固化在了网卡的ROM中,由IEEE802标准规定
                    前三个字节: OUI(Organizationally Unique Identifier),组织唯一标识符
                        可以通过前面三个字节,就知道网卡是哪个厂家生产的
                    后三个字节: 网络接口标识符
                        厂商自行分配
                当48位全为1,也就是十六进制全为F的时候,代表广播地址,说明当次是个广播
                    FF-FF-FF-FF-FF-FF
            有时候可以通过更改MAC地址蹭网
                举个例子
                    一间教室里面有多台电脑,而这些电脑都连接了交换机,可能啊学校为了防止别人蹭网,搞了一个允许上网的名单,里面记录了能够上网的机器的MAC地址,一般就是教室里的那些电脑嘛,那这个时候如果我们想蹭网,那么就拿一台自己的电脑到教室里面去,将MAC地址改成教室中某台电脑的MAC,然后网线连上交换机就可以上网了,当然了,只有允许同一个MAC进行上网,你上网了,那对应的教室那台电脑就上不了网了,交换机就不知道接受的数据该发给谁
            获取MAC地址
                就是通过ARP广播
                获取成功之后,计算机会缓存IP地址,MAC地址的映射信息,俗称: ARP缓存 
                    eg: arp -a 会列举出当前计算机的ARP缓存
                        IP地址     MAC地址     类型
                        类型
                            dynamic 表示这是通过ARP协议动态地学习到的一些MAC地址,一般两分钟后就没了
                            static  存储时间会比较久,不同的系统存储的时间是不一样的
                    如果说奥,有一天,我的缓存还在,但是实际上的呢对应的目的设备的网卡坏了,换了个网卡,那么MAC肯定也变了,那这个时候再去发送数据,第一次肯定是走的缓存,诶走了缓存发现MAC找不到了,那第一次就会发送失败,然后呢"会自动重新发送ARP广播",获取最新的MAC地址,然后放入缓存,依次类推

                    arp -d ip 删除对应的ARP缓存
                    arp -s ip mac 手动添加静态的ARP缓存(类型为static)
        IP地址(Internet Protocal Address)
            概述
                互联网中每一个主机都有一个IP地址
                最初的版本是IPv4,4个字节(32bit),2019.11.25,全球的IP地址已用完


                IPv6,16字节(128bit)
            IPv4
                按照字节区分的话
                    一个字节就是一部分
                        eg: 192.16.1.10  十进制  四个部分  那每一个部分实际上底层就是8位二进制表示嘛
                按照功能区分
                    网络标识(网络ID)+主机标识(主机ID 最后一部分)
                        同一个网段的计算机,网络ID是相同的
                    
                        网络ID: 子网掩码&IP地址 算出来的
                        主机ID: 剩下的就是主机ID
                        

            子网掩码(subnet mask)
                那我怎么知道我的网段呢?
                通过子网掩码,可以计算出网络ID(eg: 192.168.1): 子网掩码&IP地址 
                作用
                    就是拿来算网段
                        假如子网掩码是255.255.255.0 这种,那去跟IP地址(192.168.1.10)算,其实算出来就是192.168.1.0 这个就是网段 IP的前三位+.0
                    所以一般IP地址,他是从1开始的,0表示是当前网段

                判断是否在同一个网段
                    1. 看前三部分是不是一样的
                    2. 看子网掩码是不是都是一样的
                        如果光前面三部分是一样,但是子网掩码不同,那肯定不行啊,毕竟网段都是通过子网掩码算出来的嘛
                    所以必须要拿到IP地址和对应的子网掩码,才能算出当前的IP是在哪一个网段
                    eg 
                        ip地址: 192.168.1.10  子网掩码: 255.255.0.0  那么算出来网段就是 192.168.0.0 而主机ID就是: 1.10
                        
                            这种情况下可以用的IP地址就是 256*256-2 (192.168.0.0 这个表示网段 和 192.168.255.255 这个表示给当前网段下所有的机器发广播/传输数据)

                            如果网段是192.168.1.0 那么可用的IP地址就是 256-2(192.168.1.0 和 192.168.1.255)
                计算机在和其他计算机通信前,会先判断目标主机和自己是否在同一网段 
                    同一网段: 不需要路由器进行转发
                    不同网段: 需要路由器进行转发
            IP地址分类
                A类地址
                    默认子网掩码: 255.0.0.0
                    8位作为网络ID,24位作为主机ID
                    网络ID二进制 以 0 开头
                        也就是第一部分网络ID的取值范围是1~126
                        但是网络ID部分全0是不能使用的,127作为保留网段. 其中127.0.0.1 是本地环回地址(loopback),代表本机地址
                        第2,3,4部分取值范围都是0~255

                    每个A类网段能容量的最大ip数
                        256*256*256-2(主机ID全为0"网段"+主机ID全为1"代表当前网段所有机器,广播")
                B类地址
                    默认子网掩码: 255.255.0.0
                    16位作为网络ID,16位作为主机ID
                    网络ID二进制以 10 开头
                        也就是第一部分取值范围 128~191 第二部分就是0~255
                        网段最小值: 128.0  网段最大值: 191.255
                    每个B类网段能容量的最大ip数
                        256*256-2=65534    
                C类地址
                    默认子网掩码: 255.255.255.0
                    24位作为网络ID,8位作为主机ID
                    网络ID二进制以 110 开头
                        也就是第一部分取值范围 192~223, 第 2,3,4 部分的取值范围在0~255
                    每个C类网段能容纳的最大主机数: 256-2=254台
                    
                D类地址
                    以1110开头,多播地址
                        没有子网掩码之类的,就是以 1110 开头
                    第一部分的取值范围: 224~239
                E类地址
                    以1111开头,保留为"今后使用"
                        也是没有子网掩码,以 1111 开头
                    第一部分的取值范围: 240~255
                只有 A B C 类地址才能分配给主机

                
                "主机ID全为0"
                    表示主机所在的"网段"
                    比如C类的IP,那么举个例子,192.168.1.0 这个就表示是个网段 因为前三部分属于是网络ID,最后一部分是主机ID,那么主机位又为0,所以这就表示是个网段
                主机ID全为1
                    表示"主机所在网段的全部主机",那实际上往这个ip去发,那肯定就是相当于广播
                那一看IP地址就知道是哪类地址
                    比如 随便写一个 121.123.3.10 这个一看就是A类,因为第一部分 121, 取值范围在1~126

                注意
                    总之,不管是A/B/C哪类网络,网络ID部分不能为全为0
                        只是A需要注意一下,
                            A是以0开头的,那就可能全为0,而0之后的其他为全为1的话,又是个特殊的127,所以呢不能全为1
                            所以A类网络ID的取值范围 1~126
                        因为B/C是以10 110 开头的,肯定不可能全为0
                这种划分呢,只是说默认是这么划分的,比如A类的子网掩码就是255.0.0.0,某种程度上也可以自定义嘞,自定义之后第一部分的取值范围啊肯定都变了
            子网掩码的CIDR表示法(Classless Inter-Demain Routing)
                192.168.1.100/24, 代表子网掩码有24个1,也就是255.255.255.0
                    当前所在网段就是192.168.1.0
                132.210.100.200/16, 代表子网掩码有16个1, 也就是255.255.0.0  --- 注意啊,这个开头只能是128~191, 因为子网掩码16位,代表是B类网络
                    所以网段就是123.210.0.0
    子网划分
        为什么要进行子网划分?---为了避免某些情况下的IP地址浪费
            如果想要200台机器在同一个网段内,那么可以分配一个C类网段,比如192.168.1.0/24, 可以容纳254台机器嘛,放200台肯定够,空闲出来的54台也不能叫浪费
                192.168.1.0 表示网段啊,不是真正分配出去的,计算机可用的只在1~254这个范围内啊
            如果想要500台机器在同一个网段,那么就要分配一个B类网段,比如189.168.0.0/16 
                也可以分配C类网段,但是是分配两个C类网段,两个网段可以容纳254*2台机器嘛,但是这样就不在同一个网段了

                用B类网段去划分的话,范围就在189.168.0.1~189.168.255.254 这个范围, 总共65534个可用IP地址
                    那分配500个ip肯定是绰绰有余的,但是呢,这样就造成了极大的IP浪费,你这浪费了6w多个ip没用
            那如何尽量避免浪费IP地址资源呢?
                这个时候就要用到子网划分
        概述
            借用主机位作为子网位,划分出多个子网
        划分方式
            等长子网划分: 将每一个网段等分成多个子网,每一个子网段的可用IP地址数量是一样的
            变长子网划分: 每个子网的IP地址数量可以使不一样的
        等长子网划分
            假如说等分成两个子网,就是IP地址减半,那就往右移动1位
            如果等分成四个字网,就是IP地址编程四等分,那就网右移动2位
                192.168.1.00/24
                    可用IP范围: 192.168.1.1~192.168.1.62
                192.168.1.01/24
                    可用IP范围: 192.168.1.65~192.168.1.126
                192.168.1.10/24 
                    可用IP范围: 192.168.1.129~192.168.1.190
                192.168.1.11/24
                    可用IP范围: 192.168.1.193~192.168.1.254
                四个子网段
            如果等分成八个子网,那就往右移动3位
            举个例子
                现在我要用C类网段(192.168.1.0/24)去规划100台机器,但是C类网络最多是254台机器,还剩下154台浪费了就
                那现在我要进行子网划分去避免浪费,怎么划分呢? 很明显减半就大致可以了,那就是将子网掩码右移动1位嘛
                    子网掩码不24吗?我现在不让他是24,让他是25,诶那也就是说把主机ID中的前面1位拿来也当做子网,那一位要么是0,要么是1,而后7位就是主机ID,所以我就可以划分为两个子网段
                        A子网: 192.168.1.0/25      子网掩码: 255.255.255.128
                        B子网: 192.168.1.128/25    子网掩码: 255.255.255.128
                    那这个时候分成了两个子网段,那对应的子网段中的IP范围是不是就减少了? 这样的话,其实就可以对子网段中的IP进行充分利用,减少浪费
                        A子网的IP范围: 192.168.1.1~192.168.1.126
                            主机ID全0和全1不能用
                        B子网的IP范围: 192.168.1.129~192.168.1.254
                            虽然说划分了子网段,但是也要遵循当前网段下主机ID为全0,全1的情况要排除
        网段划分之后,判断是不是在同一个网段,那肯定就要去根据子网掩码的位数去算(比如24,25去算),比如说算出来一个网段的范围,然后算了之后才可以判断两个IP是否在同一个网段

        变长子网划分
            子网的长度是不一样的
            不等长的子网,它们的子网掩码也不同

            如果一个子网地址向要是原来的网段的1/2的n次方,那子网掩码就往往右移动几位,除几次2嘛

            每一个网段它们的子网掩码都不一样

            比如说要进行变长划分: 
                ip地址个数分别划分为: 4 4 32 64 128
                那么划分的网络号就对应
                    255.255.255.252/30
                    255.255.255.252/30
                    255.255.255.224/27
                    255.255.255.192/26
                    255.255.255.128/25
        两台设备在通信前,要先判断通信的设备和自己是否在同一个网段
            那怎么算的呢?
                拿着"自己的子网掩码"和"目的ip"去进行"与"运算,然后算出来一个网段,然后看看这个网段跟当前是否一致,一致的话那就通信,不一致那肯定就需要借助路由器等设备了
            举个例子
                192.168.0.10/24 可以和 192.168.10.10/16 通信吗?---不能
                    通信之前,会先判断目的ip:192.168.10.10 跟自己是否在同一个网段, 于是拿着自己的子网掩码255.255.255.0 去和ip进行"与"运算,算出来对面的网段是: 192.168.10.0, 而自己的却是 192.168.0.0, 这很明显就不一样嘛,不一样那就肯定没法通信,除非借助一些可以跨网段的设备,比如路由器以及对应的网关
                192.168.10.10/16 可以和 192.168.0.10/24 通信吗?---数据可以过去,但是回不来,所以还是不能
                    通信前,先拿着自己的子网掩码255.255.0.0 和 192.168.0.10 进行与运算,算出来发现一样的,都是192.168.0.0, 那他觉得就可以进行通信,然后数据发过去了,但是从192.168.0.10/24将数据传回来的时候,诶发现不能通信的,所以数据回不来,那还是不能通信
            网络要通的话,需要两遍都通
    超网(子网掩码往左移)
        概述
            跟子网反过来,它是将多个连续的网段合并成一个更大的网段
            子网是将一个大的网段,拆分成很多个小网段
        需求
            原本有200台计算机使用192.168.0.0/24网段,那现在想增加200台设备到同一个网段,就是400台一个网段
                直接给个B类网段吧,6w多台那就很浪费了,所以不能直接给B类网络
                    1. 用B类网段划分子网
                    2. 超网(子网掩码向左移动)
                        比如 192.168.0.0/24,192.168.1.0/24 合并,那就让他们子网掩码左移一位,变成: 192.168.0.0/23
        小问题
            192.168.0.255/23 可以分配给计算机使用吗?
                是可以的,因为子网掩码是23位,23位之后主机部分不全为0,也不全为1,所以可以
            192.168.1.255/23 可以分配给计算机吗?
                不可以,这样的话,23位之后就全是1了,是个广播地址,肯定不行
        注意
            如果想合并四个网段,那子网掩码就往左移动两位
                比如 192.168.0.0/24,192.168.1.0/24,192.168.2.0/24,192.168.3.0/24 合并为 192.168.0.0/22网段
            左移一位合并也是有条件的
                条件
                    那就是IP地址在某种程度上要是连续的,左移之后二进制位要一致,这种才能合并
                    能被2整除的(最低位是0),当前这个网段就能被合并,比如192.168.0.0 192.168.2.0 (00000010 就可以被2整除,那么对于它之后的 00000011 之类的就可以跟它合并)

                    比如
                        第一个网段的网络号以二进制0结尾,那么由他开始的连续两个网段,能够通过左移1位子网掩码进行合并
                举例
                    比如 192.168.0.0 和 192.168.1.0 这种在第三部分的末尾是连续的,这种就可以合并,如果不连续,那肯定没法合并
                    192.168.0.0 跟 192.168.2.0 ,向左移动一位就合并不了,一个是00, 一个是10
                eg 可以合并
                    192.168.0.0/24 192.168.1.0/24 ---> 192.168.0.0/23 \
                                                                        192.168.0.0/22
                    192.168.2.0/24 192.168.3.0/24 ---> 192.168.2.0/23 /
                    192.168.4.0/24 192.168.5.0/24 ---> 192.168.4.0/23


                    192.168.3.0/24 和 192.168.4.0/24 就不能合并, 都往左移动一位, 前23位二进制都不一样了,那肯定就不能合并
                ⭐️说白了要合并的话,左移之后网段部分要一样才可以合并
            判断一个网段是子网还是超网?
                先看第一部分的范围,确定他是A/B/C类网络?
                    比如192.168.10.10/22 看第一部分192,是在192~223 这个范围内,那说明他是个C类网络,C类网络的子网掩码是24位,而它是22,说明子网掩码往左移动了两位,那就是个"C类超网"
                    又比如191.168.10.10/18 看第一部分是 191, 在128~191 之间,那说明他是个B类网络,B类网络的子网掩码是16位,他是18位,说明子网掩码往右移动了两位,那就是个"B类子网"
    路由
        概述
            不同网段之间转发数据,需要有路由器的支持
            默认情况下,路由器"只知道跟它直连的网段",非直连的网段需要通过 "静态路由","动态路由" 告诉它
                eg
                    比如两个网段1,2通过网线之类的直接连上了路由器A,那么这两个网段中的设备是可以通信的
                    而比如说网段3,4通过网线直接连上了路由器B,路由器A直连了路由器B,那1,2根3,4就不是直连的,无法通信,会unreachable
                    因为路由器A,他是不知道3,4网段的,3,4接在路由器B上的,所以这个时候需要借助"静态路由","动态路由"之类的设备来告诉路由器A/B他们不知道的网段
        静态路由⭐️
            概述
                管理员手动添加路由信息  
                    就是手动告诉它,碰到3,4网段的时候,怎么走法
                适用于小规模网络
            路由表(在路由器中配置)
                配置指定ip设备
                    1. 目标设备ip地址
                    2. 255.255.255.255---代表具体设备ip地址,而不是网段
                    3. 下一跳
                配置指定网段
                    1. 目标网段
                    2. 目标子网掩码
                    3. 下一跳--->要去的路由器接口IP(不需要子网掩码,因为两个路由器这两个直连的接口ip就是在同一个网段中)
                网段和子网掩码"扩大范围"⭐️ 
                    比如之前网段是192.168.1.0,子网掩码是255.255.255.0, 那么就可以将网段和子网掩码扩成 192.168.0.0 和 255.255.0.0 ,那这样范围一扩大, 然后呢就算新增新的网段/设备,那实际上网段都是已经确定的,可以正常通信
                使用"默认路由"
                    只要发现有一条路不知道怎么走,那么就使用默认路由,目标ip是0.0.0.0,目标子网掩码 0.0.0.0, 下一跳配置默认去哪个路由器

                    一般是将连接的比较多的设备的路由器拿来配成默认路由,因为连的多嘛

                越精确的越优先

                路由器之间直连的话要在同一个网段

                那新增一个网段,我都要手动去配置一下吗?
                    不必,可以考虑扩大范围+默认路由
                        
                        

                需要在经过的路由器都进行相应的配置,因为数据传出去了之后肯定还要回来⭐️
            命令
                ip route 目标网段IP 目标子网掩码 下一跳路由IP

                Serial口是用来连接路由器的
                以太网口连接交换机
            配置之后只要是目标网段的设备,都可以进行通信,即便在目标网段新增设备,也是可以通信的,不影响

            边缘路由器配置个默认路由就比较简单


        动态路由
            概述
                路由器通过路由选择协议(RIP,OSPF)"自动获取路由信息"
                适用于大规模网络

                会去问一下跟它直连的路由器,然后就知道跟它直连的路由器直连的网段,这个路由器不知道,他再去问下一个路由器
    数据包的大致传输过程
        数据包的内容
            源IP,目标IP,源MAC,目标MAC,其他数据(请求路径,请求头...)
        传输过程
            开始传输的时候,肯定是要先通过ARP拿到MAC地址,看一下目标ip和自己是不是在同一个网段嘛?
                是的话,就走交换机/其他同网段的设备,拿到目标mac
                不是的话就要走路由器,那么就肯定先会去拿到路由器"网关MAC"(网关和当前设备是在同一个网段的)作为目标mac,拿到之后把数据传给路由器
            然后路由器接收到数据,去查路由表,看看下一跳是谁,然后转发出去
                毕竟下一跳刚开始也不知道目标MAC,所以也会先来个ARP,找到对应的目标MAC或者下个路由器的网关MAC
                然后源IP和目标IP都不变,源MAC和目标MAC发生变化⭐️
                只有到达目标设备然后返回数据的时候源IP和目标IP才会反过来

                举个例子就相当于是发送地址和目的地址不变,传输过程中就只是快递站的地址在变化,那么如果客户退货,那发送地和目的地肯定要变了
    局域网+基本概念
        网络(Network): 将多台计算机连接起来,就是一个网络
        互联网(internet): 用路由器将多个不同网段的设备连接起来,就可以理解为一个互联网
        因特网(Internet): 就是世界上最大的互联网
        ISP(Internet Service Provider): Internet服务提供商,比如移动,电信,联通,铁通...
            ISP就是提供了让我们可以用上Internet的服务,他们帮我们铺好了网线路由器blabla,自己没这个能力去拉网线光缆之类的... 我们买他的服务就可以使用Internet了
        服务器机房
            移动机房
            双线机房
            ...
        按照范围网络分类
            局域网,城域网,广域网
            局域网 
                一般是范围在几百米到十几公里内的计算机所构成的计算机网络
                比如: 公司内网,家庭,学校...

                局域网中"数据传输"中用的网络技术: 以太网(Ethernet)

                WLAN---无线局域网
            城域网(Metropolitan Area Network, MAN)
                一般范围是数十公里到数百公里,可以覆盖一个城市
            广域网(Wide Area Network, WAN)
                一般范围是几百公里到几千公里,可以覆盖一个国家,通常都需要租用ISP的线路
                比如说
                    公司分布在全国各处,然后他们网络需要互通,那这么长的网线,不可能去自己手动铺啊,那就需要去租用ISP的线路达到目的了
                路由器上有WAN+LAN,计算机接LAN,WAN口接外面的网
        常见的接口
            以太网口(网线口)
                FastEthernet: 100M
                GigabitEthernet: 1000M

                计算机,交换机,路由器
            串行接口Serial(很多针)
                路由器上和路由器相连,用的串口
                路由器和交换机连,用的以太网口
        上网方式
            1. 电话线入户

                就是平常说的ADSL电话拨号上网,非对称数字用户线路,提供上,下行不对称的传输带宽
                    下行: 从服务器拿数据
                    上行: 传输数据到服务器,发请求也是上行,上传文件之类的blabla

                    对家庭用户来讲,肯定下行更重要,有的特殊场合,对上行需求大一点


                "电话线接到光猫"
                路由器的WAN广域网口
                    WAN要接到猫上面的"网线接口"去,用来连到外边的ISP/Internet
                路由器的LAN接口
                    计算机或者其他设备接到这些LAN口去
                那数字信号怎么变成模拟信号(电话线)呢? 就需要用到一个调制解调器,进行两种信号的转换,那就是路由器和外部之间有一个光猫,那肯定你的WAN端口要接到猫的网线接口上,要不然怎么给外部发数据,发出去之前先转换


                猫(Modem)
                    调制解调器,进行"数字信号"(计算机中的0101)和"模拟信号"(电话线)的转换
                        比如通过电话线,传出去的时候是数字信号--->模拟信号,传进来的时候是模拟信号--->数字信号
                

            2. 光纤入户
                "入户光纤接到光猫上PON"

                电脑接到路由器的LAN或者无线,然后路由器的WAN连接到"光猫"(Optical Modem)的LAN,然后PON接上入户光纤

                "光猫"(Optical Modem)
                    光调制解调器,进行数字信号和光信号的转换
            3. 网线入户
                "入户网线接到路由器/电脑上"

        家用无线路由器的逻辑结构
            光猫上有口接了网线/光纤,路由器的WAN口接上光猫,然后呢有很多个LAN口,其中有LAN口接了一个内部交换机,这个交换机又接了一个无线AP,用来发送无线信号,也就是说只要连上了这个无线,那么就相当于是连上了这个内部交换机(在同一局域网),就处于同一网段,然后发送数据就可以通过路由器(和光猫连着)和外部通信
        公网IP+私网IP
            公网IP
                Internet上的路由器只有到达公网的路由表,没有到达私网的路由表
                公网IP由因特尔信息中心"统一分配和管理"
                    比如中国某个区域,分配的公网IP是什么,美国某个区域,又分配哪些IP
                ISP需要向因特网信息中心申请公网IP
            私网IP
                主要用于局域网,下面是保留的私网网段
                    A类
                        10.0.0.0/8,就一个A类网络
                    B类 
                        172.16.0.0/16~172.31.0.0/16 16个B类网络
                    C类
                        192.168.0.0/24~192.168.255.0/24 256个C类网络

                自己家的电脑ip都属于私网IP
            公网IP都是唯一的,私网IP可能会重复
        NAT(Network Address Translation)
            应用场景
                家用电脑都是私网IP,而服务器基本都在公网ip,那怎么通信呢? 可能数据发送到服务器没问题,因为有路由器,路由器可以连到外边的公网,那数据回来的时候咋办? 服务器在公网,它哪知道你这个私网IP怎么走呢? 这个时候就要用到NAT

                家用电脑给外面传数据的时候,那肯定要经过路由器,路由器就会进行(多次)NAT转换(一般是当前路由器的IP地址?),会把这个源私网IP转换成一个公网的IP,目标IP不变,还是公网IP 路由器肯定可以跟外面的世界打交道

                然后数据就可以发出去了,发出去之后能不能返回呢? 这个时候就是可以的了,因为返回时候的目的IP地址就是那个NAT转换后的公网IP地址,就可以定位到那个家庭路由器,然后路由器拿到数据之后,他肯定记录了这条数据是对应哪个设备嘛,然后就把数据返回给对应设备
            概述
                私网IP访问Internet需要进行NAT转换为公网IP
                这一步可以由路由器来完成
                可以"节约公网IP资源"
                    这个就不一定要求说全世界每一台设备的ip都要不同,同一个网段中的ip地址就没有必要用公网IP地址,用私网IP就可以了
                会隐藏内部真实IP
                    比如说网警查,也只是查到对应的NAT的IP
                    或者人家直接查ISP
            NAT分类
                静态转换
                    手动配置NAT映射表
                        私网IP ---> 公网IP
                    "一对一转换",不能达到节约公网IP的地址
                动态转换
                    定义一个外部的地址池,动态随机转换
                        有个池子,里面可能有好几个公网IP,然后呢转换的时候,遇到一个私网IP,就去池子里面拿一个公网IP出来,进行映射转换
                    "一对一转换",无法达到节约公网IP的地址
                PAT(Port Address Translation) ☆
                    多对一转换,最大程度节约公网IP资源
                        多个私网IP对应一个公网IP,那怎么区分是哪一个私网IP发送出去的呢?
                    采用"端口多路复用方式",通过"端口号"标识不同的数据流
                    "目前最广泛的NAT实现"
        交换机也可以直接接同一个网段的设备,跟型号有关,有的型号有那种接口,这个时候就像个交换机,同一网段直接通信

        为什么使用路由器在跨网段通信/ping的时候,第一次会丢失数据?
            因为比如说在A网段机器AA,第一次要跟B网段机器BB通信,那么刚开始他就要发送ARP,去获取路由器对应A网段的网关的MAC地址,拿到之后,就直接把数据包发给路由器,路由器收到之后呢,它只知道BB在对应的这个网段上,但是他不知道BB的MAC地址,所以会直接把数据包扔了(忙不过来,又要ARP,又要发数据),然后呢通过B网关去发个ARP给BB机器,拿到对应的MAC地址存起来,所以第一次通信,数据会丢失,以后的通信才会成功

            本质就是第一次路由器不知道对应机器的MAC地址,然后丢了,然后它发送ARP拿到之后,以后就知道了嘛
    网络分层
        分层模型
            OSI七层模型
            物理层---数据链路层---网络层---传输层---会话层---表示层---应用层
            四层模型(实际应用)---TCP/IP协议
                实际应用过程中应用到的
                网络接口层---网络层---传输层---应用层
            五层模型(学习研究)
                物理层---数据链路层---网络层---传输层---应用层
        
        可靠传输
            就是比如要传输的数据很大,那么不可能说我一次性给你传过来,那不太现实,就很有可能需要传输多次,那如果传输的过程中,由于网络闪断啊或者其他之类的原因,导致数据少了/丢失了,那咋办,要保证可靠传输,那肯定就是说数据要进行重新发送啊,或者只发送丢失的部分,这样才能实现可靠传输嘛,这个一般是在传输层进行保证的

            所以少了传输层就不行

            网络层会帮我们加上源IP+目标IP
            数据链路层会帮我们加上源MAC+目标MAC

        "但凡少一层,都行不通"
        分层内容
            应用层
                协议
                    FTP,HTTP,SMTP,DNS,DHCP
                传输的数据
                    报文,用户数据
            传输层
                协议
                    TCP,UDP
                传输的数据
                    段(segments)
            网络层 
                协议
                    IP,ARP,ICMP
                传输的数据
                    包(packets)
            数据链路层
                协议
                    CSMA/CD,PPP 
                传输的数据
                    帧(Frames)
            物理层
                传输的数据
                    比特流(Bits)---传到网线上
        物理层(Physical)
            作用
                主要是定义了接口标准,线缆标准,传输速率,传输方式等

                就是"定义设备标准"
            eg
                路由器上接口依据什么标准啊,速度又没有限制啊,网线用什么材质啊,形状啊,双绞线,光纤之类的...
            模拟信号+数字信号
                模拟信号(Analog Signal)---波浪线
                    连续的信号,适合长距离传输
                    抗干扰能力比较差,收到干扰的时候波形就会变形,很难纠正
                数字信号(Digital Signal)---010110...
                    离散的信号,不适合长距离传输
                    抗干扰能力比较强,受到干扰时波形失真可以修复
                        就算受到干扰,也知道哪里是高的,哪里是低的
            数据通信模型
                局域网通信模型
                    PC---数字信号(网线)---[集线器/交换机]---数字信号(网线)---PC 
                    网线是不能超过100m的⭐️
                广域网通信模型
                    PC---数字信号(网线)---[调制解调器]---模拟信号(电话线)---[调制解调器]---数字信号(网线)---PC

                    PC---数字信号(网线)---[光电转换器]---光信号(光纤)---[光电转换器]---数字信号(网线)---PC

                    电话线是不能传输数字信号的,只能传输模拟信号,数字信号是不支持长距离传输
                    中间需要调制解调器进行转换
            信道
                概述
                    信息传输的通道,一条传输介质上(比如网线)可以有多条信道
                    一根网线,不可能说同一时间就只能传输一条数据吧
                单工通信
                    信号只能往一个方向传输,任何时候都不能改变信号的传输方向
                        比如从来都只可以从左往右传输,不能从右往左传输,这种就是单工通信
                    eg: 无线电广播,有线电视广播  都是单向广播的
                半双工通信
                    信号可以双向传输,但必须是"交替进行","同一时间只能往一个方向传输"
                    eg: 对讲机
                全双工通信
                    信号可以同时双向传输
                    eg: 手机打电话
        数据链路层(Data Link)
            链路 
                从1个节点到相邻节点的一段"物理线路"(有线/无线),中间没有其他交换节点(比如交换机之类的)
                    如果AB跟集线器这种设备连接,那实际上AB还是处于同一链路的,因为集线器没有智商,收到数据直接发出去了,就相当于一根网线,那也是不经过交换节点
                    如果AB中间连了个交换机,那就是两条链路

            在一条链路上传输数据的时候,需要有"对应的通信协议"来"控制数据传输"
            不同类型的数据链路,所用的通信协议可能是不同的
                比如路由器和路由器之间的链路 与 PC和交换机之间的链路,用的协议那很可能是不一样的
            信道类型
                "广播信道"
                    CSMA/CD 协议,比如同轴电缆,集线器等组成的网络
                    比如这种链路上就只能进行广播操作,发出去都能接收到,就是广播信道嘛,那不用CSMA/CD这种协议,人家怎么知道你这个是广播呢?
                "点对点信道"
                    PPP协议,比如两个路由器之间的信道
            三个基本特性
                不论什么链路,都是要有这三个步骤
                封装成帧
                    把网络层的数据包拿过来封装成"帧",IP数据包就是帧的数据部分,然后再加上"帧首部"(包含帧开始符)和"帧尾部"(帧结束符)
                    帧的数据部分
                        就是网络层传递下来的数据包(IP数据包,Packet)
                    最大传输单元MTU(Maximum Transfer Unit)
                        上一层(网络层)传递过来的IP数据包大小不能超过MTU
                        "每一种数据链路层协议都规定了所能够传送的帧的数据长度上限"
                            eg: 局域网中"以太网"(CSMA/CD)的MTU为1500个字节
                    帧开始符+帧结束符
                        帧最终是在网线上进行传输的嘛,一连串的帧跑在网线上,那网线上这么多帧,我去怎么区分哪一部分属于哪个帧呢? 这个时候就要用到帧开始符+帧结束符来标识不同的帧
                透明传输
                    帧开始符+帧结束符,两个符号占两个字节嘛,那如果说我的数据部分中有一部分T跟这两重复了,那会不会说是我从帧首部开始读,读着读着就读到T,那就结束了???后边数据不就被抛弃了吗?
                    SOH(Start of Head,End of Tail)
                    所以,数据部分一旦出现SOH,EOT,就需要进行"转义"
                        举个例子
                            在待发送的帧中,如果发现SOH/EOT/ESC,那么就添加ESC进行"字节填充"(一个字节变两个字节),那么在网络中进行传输的时候,那就是转义之后的样子,那么到达目标设备之后呢,就会一一去除转义字节
                    透明 
                        发送的时候是A,拿到的时候也是A,就是这个转义的过程啊,我们根本感觉不到它的存在,"相当于透明的"
                差错校验
                    帧首部: 帧开始符+数据链路层首部
                    帧的数据部分
                    帧尾部: 帧结束符+FCS(用来做差错校验的)
                    
                    
                    FCS:
                        根据帧的数据部分+数据链路层首部 "计算"出来的
                        场景
                            如果我们的数据帧在传输过程中收到了干扰,那么这个时候怎么去校验它是否准确呢? 肯定得有个标志/计算的东东来进行判断啊
                        校验过程
                            它会拿着帧的数据部分+数据链路层首部去计算出一个值,这个值就是FCS,那么目标设备拿到数据之后,它也是会去计算 帧的数据部分+数据链路层,看看这个结果和FCS是否一致
                                如果一致,那说明这个数据是没什么问题的,网卡进行接收
                                如果结果和FCS不一致,说明数据有问题,网卡就会把这个数据丢掉,抓包工具也抓不到这个数据,因为网卡都把他丢掉了
                        
                        同一个协议下,数据链路层首部是一样的,那么也就是说这种情况下,数据变了,FCS就变了,数据没变,FCS就没变,FCS是前两个玩意儿算出来的
            不同的链路类型,在封装成帧的过程中,帧首部和帧尾部加的东西是不一样的
                那也就是说,在局域网的链路中传输的数据,和在路由器与路由器的链路中传输的数据是不一样的,因为他们的链路类型不一样,采用的协议也不一样,局域网可能采用的是CMSA/CD协议,而路由器之间用的是PPP协议,那么在帧首部和帧尾部添加的数据也就不一样(对应的协议添加对应的数据),所以虽然是同一个网络层的数据,但是在这两种链路中传输的时候,"包装之后的比特流会有所差别"

                即便协议/链路不同,中间的帧数据部分不会变啊,那个是从网络层下来的,怎么会变呢? 只是说根据对应协议在两端添加不同东西而已, 包装之后的肯定就不一样了嘛
            协议
                CSMA/CD协议(载波侦听多路访问/冲突检测)---传输"以太网帧"---"同轴电缆","集线器等"组成的网络
                    概述
                        一般是在同轴电缆,集线器等组成的网络
                        比如说集线器,采用半双工通信,A在发数据的时候,B就不能发,那这个时候就需要一个协议去规定大家应该怎么发送
                        
                    载波侦听/多路访问/冲突检测
                        "载波侦听"
                            这个接口可以监听到当前这个信道上有没有人在发送数据,有没有信号在传输
                            如果有人在发送,那就不发
                            如果没人发送,那就可以发送 
                        "多路访问"
                            大家都可以发送
                        "冲突检测"
                            比如说A在往集线器发送数据,B也在往集线器发送数据,那么势必要产生冲突,那产生冲突之后信号就会弹回去,那A接口收到这个信号之后,怎么判断当前这个信号是反弹回来的信号还是目标设备返回回来的信号呢? 这个时候就需要冲突检测,检测一下看看到底是个啥
                    
                        因为是半双工通信,所以要采用上面三种方式来约束/规定
                    以太网/以太网帧
                        使用了CSMA/CD协议的网络可以称为是"以太网"(Ethernet),数据链路层包装之后的数据帧被称之为是"以太网帧",传输的就是这个以太网帧
                            如果使用了CSMA/CD协议的网络就是使用了以太网技术


                        用"交换机"组建的网络,已经支持全双工通信,"不需要再使用CSMA/CD",但它传输的帧依然是"以太网帧"
                        所以交换机组建的网络,依然可以叫做"以太网"

                    "以太网帧"两种标准
                        Ethernet V2标准---使用的最多,传输的格式是以太网2的格式
                        IEEE的802.3标准
                    "以太网帧"检测冲突的条件
                        为了能够检测正在发送的帧是否发生了冲突,以太网的帧至少要64字节(信道的两倍)
                            如果帧太短,那么发生了冲突,诶我已经发送完了,冲突回来,我就不知道这到底是个冲突还是个正常返回来的信号
                            那如果说我的帧足够长,发生了冲突,但是实际上我还在继续发送(因为帧足够长),那么我没发完信号就回来了,说明怎么样,就说明发生了冲突,那这样就可以判断
                            一般来讲帧要是信道的两倍 "至少64字节" 32字节就是100m 网线 ⭐️

                            那如果数据本身就很小,就算包装到数据链路层也没有64字节,那咋办,不用担心,数据链路层会自己去进行填充
                    注意
                        交换机不采用CSMA/CD协议,但是传输的"比特流"和采用CSMA/CD协议的链路是一样的,因为都是采用的"以太网帧"
                        数据封装到数据链路层就完成了,物理层只是用来进行传输的

                    Ethernet V2的格式
                        MAC帧
                            目标MAC地址(6)+源MAC地址(6)+网络类型(2,IPv4/IPv6)+ IP数据包(46~1500) +FCS(4)
                                            首部                                数据            FCS
                            构成了最小帧64字节
                        
                        以太网V2是不需要"帧开始符"和"帧结束符"
                            那V2没有这两个,怎么判断帧什么时候开始,什么时候结束呢?
                                以太网使用了"曼彻斯特编码",接收端接受帧过程只要发现"没有信号跳变",就认为"帧结束"
                                用了曼彻斯特编码,就不需要帧开始符+帧结束符
                            数据传到物理层的时候,会插入在首部之前插入8个字节
                                7个字节: 前同步码
                                1个字节: 帧开始定界符
                                可以获取一些比如时钟频率之类的
                        首部
                            源MAC+目标MAC+网络类型
                        以太网帧
                            组成
                                首部+数据+FCS 
                            数据
                                数据的长度最少是 64-6-6-2-4=46 字节,最长不过1500字节
                                
                                当数据的长度小于46字节的时候/网络层传下来的数据小于46,数据链路层会在数据的后面加入一些字节进行"填充",接收端会将填充的字节去掉
                            长度范围
                                64~1518(目标MAC+源MAC+网络类型+数据+FCS)
                PPP协议(Point to Point Protocal)---点对点协议(两个路由器直连的情况⭐️)
                    首部(帧开始符+Address+Control+协议)+数据+尾部(FCS+帧结束符)

                    Address字段: 0xFF,形同虚设,点到点是不需要源MAC,目标MAC的
                        点到点就只有一条线连着,不是A传B就是B传A,那肯定就不需要源MAC和目标MAC了
                    Control字段: 0x03,目前没什么用
                    Protocal: PPP内部用到的协议类型
                    帧开始符+帧结束符: 0x7E

                    传输的就是PPP帧了,CSMA/CD协议传输的是"以太网帧",但是里面封装的网络层的数据是一样的(这个是从网络层来的嘛)
                        什么源IP啊,目标IP啊,都是写在网络层的首部的,所以在整个网络中进行传输的时候,不管是经过路由器还是交换机,它的源IP和目标IP都不会变,变的是源MAC和目标MAC

                        如果路由器和路由器直连,那用的就是PPP协议,传输的是"PPP帧"(没有MAC地址信息)
                        如果路由器(网关口)---交换机---(网关口)路由器,传输的是"以太网帧"(包含源MAC+目标MAC),交换机嘛

                        为啥以太网帧就需要MAC地址呢?
                            因为以太网帧适用于是广播信道,广播信道那肯定是信号发出去了大家都收的到,都收的到肯定需要通过MAC地址来进行判断
                    
                    存在透明传输(填充转义字符)
            网卡
                工作在数据链路层+物理层
                功能⭐️
                    具有数据链路层的功能
                        帧的封装与拆封,帧的差错校验,介质访问控制(CSMA/CD)
                    物理层的功能
                        物理连接+数字信号同步,数据的编码与解码
                流程
                    比特流进来  
                        网卡先进行差错校验(FCS),如果校验不通过,那就直接丢掉,如果校验通过,那就接受并进行帧的拆封,然后传递给上层

                        WireSHark抓到的帧没有FCS,因为它抓到的是"差错校验通过的帧"(帧尾的FCS会被硬件去掉),是抓不到差错校验失败的帧
                            那如果网关差错校验都没通过,网关都把它丢了,那自然也是抓不到的了
            注意
                如果数据量很大,超过了1500个字节,那肯定就需要分多次发送出去,网络层发出去很多帧
                集线器工作在物理层
                    可以理解为就是一根网线嘛,又不需要差错校验啊,帧的封装/解封,透明传输之类的...也不会去判断什么源MAC和目标MAC
                交换机工作在数据链路层⭐️ 
                    要传输以太网帧嘛
                路由器工作在网络层+数据链路层+物理层
                    要知道IP嘛,然后呢又传输以太网帧/PPP帧
        网络层☆☆☆
            概述
                网络层数据包(IP数据包,Packet)由 "首部"+"数据"(一般是由传输层传递下来的数据Segment) 两部分组成
                "数据部分不一定全是传输层传下来的"
                    有的协议没有传输层,比如说ARP,IP,ICMP协议,直接就是经过网络层传输,不经过传输层
                    比如发送一个ICMP的请求
                        那直接就是 网络层首部(protocal:IMCP...)+数据(ICMP首部+ICMP数据)
            图示
                0    4       8        16    19    24     31
                |版本|首部长度| 区分服务 |      总长度        |-----------------
                |         标识         | 标志|    片偏移    |
                |  生存时间   | 协议    |   首部校验和       |     首部
                |               源IP地址                   |
                |               目标IP地址                 |
                |     可选字段(长度可变)            |  填充  |-----------------
                |               数据部分                   |

            首部(固定部分(20字节)+可变部分)
                固定部分(0~32位,一层就是4个字节,总共5层)
            
                版本(Version)
                    标识是IPv4还是IPv6
                    占4位
                        0b0100: IPv4
                        0b0110: IPv6
                    
                首部长度(Header Length)
                    用来标识当前首部的长度,包含可变部分
                    占4位
                        抓包工具中首部长度的二进制值*4才是真正的首部长度
                        0b0101(最小值) 算出来是5,5*4=20, 20是首部的固定部分的长度
                        0b1111(最大值) 首部最长15*4=60个字节,也就是说可变部分最大是40字节(最大60-固定20=40)

                        不够4的倍数要填充到4的倍数
                区分服务
                    可以用来提高网络的服务质量(QoS,Quality of Service)
                        用来跟其他数据包做个服务区分,优先级相当于是,"按照服务区别对待"
                    占8位
                    eg
                        客户端---路由器...---服务器 
                        中间经过这些路由器的时候,那路由器就要看你有没有使用区分服务,如果使用了某种区分服务,那你这个数据包就优先通过,要不然和其他数据包一样,平等对待
                总长度
                    用来标识当前整个IP数据包(首部+数据部分)的长度/大小
                    占16位
                        两个字节,范围: 0~65535字节

                        由于帧的数据不能超过1500字节,所以过大的IP数据包,需要"分片"成(fragments)传输给数据链路层
                        "每一层都有自己的网络层首部"(IP首部)
                标识+标志+片偏移
                    概述
                        当网络层数据过大时,需要进行分片然后传递给数据链路层,那分了很多片,我如何得知,哪些片属于同一个IP数据包呢?
                        这个时候就要用到标识+标志来进行区分
                        "每一层都有自己的网络层首部",分片的时候,先给每一个片加上网络层首部,这样每个片都会拥有自己的网络层首部,然后再传给数据链路层进行封装
                    标识(ID)
                        占16位
                        数据包的ID,当数据包过大进行分片时,"同一个数据包的所有片的标识都是一样的"
                        有一个计数器专门管理数据包的ID,每发出一个数据包,ID就+1
                    标志
                        作用
                            分了这么多片,要进行合并的时候,我怎么知道当前的这个片后面是否需要继续拼接呢? 当前这个片是不是最后一片呢? 这时候就需要用到标志(3位),看他第二位和第三位来进行判断
                        占3位
                        第一位(Reserved Bit): 保留位0
                        第二位DF(Dont Fragment): 1代表不允许分片,0代表允许分片
                        第三位MF(More Fragment): 1代表不是最后一片,0代表是最后一片
                    片偏移(Fragment Offset)
                        作用
                            数据包分了这么多片传给数据链路层,那我怎么知道哪一片是属于哪一部分呢? 
                            这个时候就要用到片偏移来确定它具体是属于数据包的哪一部分
                        占"13"位
                        片偏移*8=字节偏移
                            代表当前片是从原始数据包的多少字节开始

                        字节偏移: 从多少字节开始
                            比如当前这一片从1400字节的部分开始,那么字节偏移就是1400

                            但是呢,有的时候可能诶,字节偏移会很大,因为数据总长度⭐️是0~65535, 16位,而片偏移只占13位,那很有可能有的时候存不下哦,所以要让片偏移除以8,2的三次方,16-13 嘛,然后那就存的下了

                            所以算这个字节偏移的时候,那就是片偏移要乘以8,才能得到字节偏移
                        每一片的长度一定是8的整数倍⭐️
                首部校验和
                    作用
                        像FCS,用来做校验的,就是将首部中的那些数据拿来通过一定的算法,进行计算,算出来的值作为"首部校验和"
                    占16位
                协议
                    作用
                        表明所封装的数据是使用的什么协议
                    占8位
                    协议
                        ICMP    IGMP    IP      TCP     EGP     IGP     UDP     IPv6    ESP     OSPF
                        1       2       4       6       8       9       17      41      50      89      十进制
                        
                        如果是对应的协议类型,那么在首部中的协议那8位中存储的就是这些值
                生存时间TTL(Time To Live)
                    概述
                        每个路由器进行转发之前,会将TTL-1,当TTL>0的时候才会进行转发,一旦发现TLL减为0,路由器就会返回错误报告(过期),不会再进行转发
                    作用
                        防止路由死循环
                            举个例子,路由器A和路由器B,他们的默认路由都是对方, A<--->B,如果没有TTL,那一个数据过来,就无线循环在这两个路由器中跳,那还得了? 
                            所以搞个TTL作为限制,到达最大次数之后,就会返回错误信息
                            一般TTL几十就算多的了
                    占8位
                    不同的操作系统,默认TTL不同,可以根据TTL推测服务器的系统
                        Windows 128
                        Linux(2.0)   64
                        Linux(2.2..) 255
                        MacOs   60
                        MacOSX  64
            命令
                ping命令 
                    ICMP协议 
                    ip /?
                        查看ping的用法
                    ping ip地址 -l 数据包大小
                        发送指定大小的数据包
                    ping ip地址 -f
                        不允许网络层分片
                    ping ip地址 -i TTL 
                        设置TTL的值
                通过tracert,pathping命令,可以跟踪数据包经过了哪些路由器
                    tracert www.baidu.com
                    pathping www.baidu.com
        传输层☆☆☆(TCP/UDP)
            传输层有两个协议
                TCP(Transmission Control Protocol)---传输控制协议
                UDP(User Datagram Protocol)---用户数据报协议
            区别
                                TCP                        UDP
                连接性          面向连接                   无连接
                可靠性      可靠传输,不丢包         不可靠传输,尽最大努力交付,可能丢包
                首部占用空间     大                          小
                传输速率         慢                          快
                资源消耗         大                          小
                应用场景    "浏览器",文件传输,邮件...      音视频,直播,比较适合实时的场景
                应用层协议    "HTTP,HTTPS,FTP,SMTP,DNS"     DNS

            面向连接
                客户端和服务器要通信,首先要建立连接,三次握手,四次挥手(断开连接) 
                建立连接之后相当于开通了一条管道,然后在管道中进行传输

                无连接: 直接把数据扔过去,不管对方有没有收到
            可靠传输
                比如说发送100k数据,但是由于某种原因,结果检测出来丢了一些数据,那就要重新发送

                不可靠传输: 只是尽最大努力把数据传过去,可能会产生丢包,因为不会去检测数据是否完整
            像HTTP/HTTPS/FTP...这些协议,它的传输层用的就是TCP协议
                所以HTTP/HTTPS广泛用在浏览器中
                    展现网页,不可能说传着传着就少了一些字啊,所以必须要是可靠传输,使用TCP
            有的DNS可以用TCP,有的DNS可以用UDP

            UDP(User Datagram Protocal)---数据格式
                概述
                    UDP是无连接的,减少了建立和释放连接的开销
                    UDP尽最大努力交付,不保证可靠交付
                    因此不需要维护一些复杂的参数,"首部只有8个字节"("TCP的首部至少20字节")
                图示
                    首部:8个字节
                    源端口+目的端口+长度+校验和
                    0                   15 16                   31
                    |    16位源端口号    |   16位目的端口号        |
                    |    16位UDP长度     |   16位UDP校验和        |
                    |                   数据(若有)                |
                UDP长度 
                    占16位,首部的长度+数据的长度 
                    就是UDP数据报的总长度
                UDP校验和 
                    计算"校验和"最常见的两类
                        1. 只算首部
                            比如说: 网络层中的首部校验和
                        2. 算上首部+数据
                            比如说: 数据链路层中的FCS
                    UDP校验和计算
                        伪首部+首部+数据 
                        伪首部(12)---使得检错能力更强
                            源IP(4)+目的IP(4)+保留位(1,默认为0)+协议(1字节,0x11(代表是UDP协议))+UDP长度(2)

                            伪首部仅在计算校验和的时候起作用,并不会传递给网络层

                            增强检验功能,甚至包含了一些网络层的东西,比如源IP之类的
                        首部(8)
                            源端口(2)+目标端口(2)+长度(2)+校验和(2)
                        数据

                        UDP数据报: 首部+数据 
                端口 
                    UDP首部中端口是占用2字节16bit
                    可以推测出端口号的取值范围是:0~65535

                    客户端的源端口是"临时"开启的"随机端口"
                        从服务器返回回来的时候,源端口变目标端口,目标端口变成源端口
                        客户端用完之后,就会把端口关掉,服务端的端口是一直开着的,不变

                    防火墙可以设置开启/关闭某些端口来提高安全性
                    一些协议常用的端口
                        HTTP: TCP+80
                        HTTPS: TCP+443
                        FTP: TCP+21
                        MySQL: TCP+3306
                        DNS: UDP\TCP+53
                        SMTP: TCP+25
                        POP3: TCP+110
                    命令
                        netstat -an: 查看被占用的端口
                        netstat -anb: 查看被占用的端口,占用端口的应用程序
                        telent 主机 端口: 查看是否可以访问主机的某个端口
            TCP(Transmission Control Protocal)
                要点
                    "可靠传输"
                        如果传输的数据量过大,那就需要分段传输,那如果在传输的过程中有丢包之类的,导致数据不完整,那么这个时候会将丢失的包重新发过去
                    "流量控制"
                        客户端在发请求给服务器的时候,会告诉服务器,客户端接受窗口的大小
                        就是传输层有个窗口,相当于是缓存,用来接收数据用的,它肯定是有大小限制的
                        
                    "拥塞控制"

                    "连接管理"
                        建立连接 
                        释放连接

                    就是通过首部的一些字段去保证这三点,所以首部会比较复杂
                首部
                    20个字节的固定首部
                    图示
                        0       4       8 10    16          24          32
                        |           源端口       |         目标端口        |
                        |                       序号                     |
                        |                      确认号                    |
                        |数据偏移|   保留   |标志位|          窗口          |
                        |           校验和        |         紧急指针       |
                        |           可变部分选项              |    填充    |
                        |                       DATA                     |

                    数据偏移(首部长度)
                        占4位,取值范围是: 0x0101(5)~0x1111(15)
                        要乘以4,才是首部长度,而首部最小是20字节嘛,所以数据偏移的最小值是 0x0101, 最大值是15,那也就是说首部的最大长度是60
                        
                        跟网络层的首部有点像奥,都是固定部分20字节,可变部分最大40字节
                        而且网络层的首部长度也是要*4,才是最大长度

                        主要是拿来算首部长度
                        可以理解为,首部长度是多少,数据呢就往右边偏移多少,所以数据偏移对应首部长度

                        注意(诶数据偏移只是记录了首部长度,我怎么算数据部分的长度呢?)
                            UDP中2个字节16位去记录(首部+数据长度),而TCP中则是通过"数据偏移"(4个位)仅记录"首部长度",没有记录数据长度

                            UDP首部中占16位的长度字段是"冗余"的,纯粹是为了保证首部是32bit对齐(因为要保证首部的长度是4/8的倍数,其实很大程度上不需要用到16位)
                            TCP\UDP的数据长度,完全是可以由"IP数据包的首部"(网络层)推测出来
                            传输层的数据长度=网络层的总长度-网络层的首部长度-传输层的首部长度

                    保留 
                        占6位(或者占3位,标志位占9位),全为0
                        没啥用,只是占个位置而已
                    标志位
                        总共6个标志,每个标志占1位,总共占6位
                    源端口号+目标端口号
                        每个都占16位,2个字节 
                    校验和(checksum)
                        占16位 2个字节

                        伪首部+首部+数据

                        伪首部(和UDP的差不多,基本一样,也是从网络层拿的数据,没有网络层也可以把伪首部构建出来)
                            占12字节,仅在计算校验的时候起作用,并不会传递给网络层
                            源IP(4)+目的IP(4)+保留位(1,默认为0)+协议(1字节,6(代表是TCP协议))+TCP长度(2)
                    标志位☆☆☆
                        占6位(或者占9位),一个标志占1位,如果是9位,前三位基本没用

                        URG(Urgent)
                            当URG=1的时候,"紧急指针字段才有效",表明当前报文段中有紧急数据,应优先尽快传送

                            紧急指针中放的是紧急数据的长度
                                比如,当URG=1的时候,如果紧急指针中放了个8,那么在传输层的数据部分前8个字节都是属于紧急数据,需要优先发送

                                如果URG=0,紧急指针中放啥都没用
                        ACK(Acknowledgment)---确认
                            当ACK=1的时候,确认号字段才有效
                        PSH(Push)
                        RST(Reset)
                            当RST=1时,表明连接中出现严重差错,必须释放连接,然后"重新建立连接"
                        SYN(Synchronization)---建立连接
                            当SYN=1,ACK=0时,表明这是一个建立连接的请求

                            三次握手
                                第一次(客户端向服务端发送"建立连接"请求)  SYN
                                    SYN=1,ACK=0
                                第二次(服务端向客户端回复"同意建立连接")  SYN,ACK
                                    SYN=1,ACK=1
                                第三次()
                        FIN(Finish)---释放连接
                            当FIN=1,表明数据已经发送完毕,"要求释放连接"
                    序号(Sequence Number)
                        32位 4个字节
                        概述
                            首先,传输过程中的每一个字节都有一个编号
                            TCP的传输是面向字节流的,每一个字节都有自己唯一的编号,连续的字节,他们的编号也是连续的

                            "在建立连接后",序号代表: 这一次传给对方的"TCP数据部分"的"第一个字节"的编号
                                比如建立连接之后,客户端发送了HTTP请求到服务端,然后服务端返回数据,那可能数据是分段传输的,第一段比如传输了三个字节回来,那么此次传输的TCP首部中的序号就是第一个字节的编号,第二段传了4个字节回来,那此次TCP首部中的序号就是此次第一个字节的编号
                    确认号(Acknowledgment Number)
                        32位 4个字节
                        概述
                            "在建立连接后",确认号代表: "期望"对方下一次传过来的"TCP数据部分"的"第一个字节"的编号

                        描述
                            建立连接之后,客户端给服务端发送了HTTP请求,服务端进行回复,那如果是分段传输的,那假如说分了三段,1~100,101~200,201~300, 那第一次肯定是发1~100给客户端,好,那么这个时候回复的时候TCP首部中的"序号"就为 1,然后客户端接收到之后,那它肯定希望的是我还要继续接受呀,那我接收到100了,下一次开始的编号肯定是101,好,那么这个时候客户端再给服务端发请求(用来告诉服务端数据接收到哪里了,一般这个时候"数据部分"为空),那它的TCP首部中的"确认号"就是100,就是期望对方下一次传过来的"TCP数据部分"的"第一个字节"的编号,下一次服务端往客户端传数据的时候,那个序号就是101,这个就是建立连接后确认号的作用

                            怎么说呢,就是在建立连接后,分段传输的时候,期望下一次传的数据中TCP首部的"序号"是多少(因为序号就是此次传输中第一个字节的编号)⭐️
                        
                        建立连接后,期望下一次传过来的数据首部中的"序号"(第一个字节的编号)
                        建立连接之前,序号和确认号有其它含义
                    窗口
                        占2字节 
                        有"流量控制"功能,用以告知对方下一次"允许发送的数据大小"(字节为单位)--->一般容量都还可以(0~65535)
                        
                "可靠传输"(怎么实现的)
                    ARQ(Automatic Repeat-reQuest)---自动重传请求/停止等待ARQ协议,最初的做法
                        ⭐️发一个确认一个,阻塞式的
                        A要发送3个数据M1,M2,M3给B
                            无差错情况
                                先发送M1给B,B收到之后进行回复确认,A收到确认之后,再发送M2给B,然后B收到后再进行确认...
                            超时重传
                                当A发送M1给B的时候,中途出了点小叉子,可能丢失或者某一部分丢失,那B收到之后就会丢弃由差错的报文,而且"不会进行回复确认",然后A在那等啊等,结果发现超时了,然后就"重新再次发送M1"给B,然后B就概率收到并回复,然后A收到回复之后,再发送M2给B
                            确认丢失
                                返回的确认也可能会丢掉,那实际上B是已经收到了M1,但是由于确认丢失了,A等待了一段时间之后,没收到B的确认,就认为超时了,那然后就会重新发送M1给B,但是实际上B是收到的,所以这个时候当B收到第二次M1时,就会"丢弃重复的M1,重新确认M1"
                            确认迟到
                                可能第一次发送的数据到达B后,然后B收到了M1,然后回复确认给A,那可能这次回复不知道啥原因,走路由器走绕了,然后呢导致这个确认啊很久都没有给到A, 然后过了一段时间,A就认为超时了,重发M1,然后B收到,就会丢弃之前的M1,再重新回复确认给A,这一次A可以正常拿到确认,然后继续传M2...  等了一段时间之后,消失的第一次M1确认突然到达A, 实际上这个时候可能数据都已经发完了,然后呢,A会"收下迟到的确认但什么也不做"
                        
                        这样"确实可以保证可靠传输",所以叫停止等待ARQ协议,"停止并等待响应结果",不是一次性全部发出去,而是一个一个发

                        存在的问题
                            效率很低下啊,要接收到确认之后才能发下一次,很deer
                            如果1000个字节分10次发,一次需要1s,那发这1000个字节需要10s才能发出去,太慢了吧
                        改进
                            使用 连续ARQ协议+滑动窗口协议
                    连续ARQ协议+滑动窗口协议
                        A要发M1,M2...M8给B
                            发送数据进行分组,发送完,等待确认

                            第一次连续发送M1...M4 4个数据给B,然后B连续收到M1...M4之后才会进行确认一次(只会告诉A收到了M4,等价于M1...M4都收到了),A拿到确认之后,再发送M5...M8给B,B再进行确认回复收到了M8
                        滑动窗口协议
                            就是有个窗口大小,M1...M4 4个大小就是窗口大小,这个是B告诉A的,B的传输层有个缓存,缓存有多大,就决定了A一次性可以发多少个数据,也就是决定了A那边的窗口大小
                                比如B的缓存有400字节,那A就可以发送400字节,A的窗口就是400字节
                                    但是要分包发送(每个包发送的时候都要加上TCP首部),分4个包发送(M1...M4),每个包都有自己的"序号"(TCP首部中的那个序号),分包之后把这些包一次性发过去,发完并收到确认之后A的窗口就往下滑动

                                    收到第一批的包之后,就会进行回复确认,然后呢会带上确认号(ACK=1,ack=401),这样子,就是告诉A它收到了前四个包的数据,期望下一次收到序号为401的包

                                    发送方收到确认之后,发送方会将之前发送的数据从缓存中删除,因为对方已经收到了,再保留就没啥意义了,窗口滑到M4~M8,分包将这几个发出去(发出去的时候,TCP首部包含"序号"信息),接收方接收到之后,会将之前已经读取的报文删除掉,因为这些数据已经传给了上一层了,留着也没啥意思了

                                    如果第二次中,601第7个包丢失了,其他三个401,501,701都可以正常接收,那么接收方就只会接受401,501,701这三个包,对于601这个包咋办呢? 这个时候就会回复一个"sack"(selective ack,选择确认),告诉客户端只重新发送第7个分组

                                    然后客户端收到的如果是"sack",那么就只会重发第7个,如果不是呢,就继续根据来的ack(比如说是601),往后移动4个,分包发过去

                                    确认的过程中,也会告诉客户端当前窗口是多大(不是一成不变的,可能会窗口大小会发生变动)

                                    每个包的大小也不是确定的
                            
                        发送方的窗口大小一般是由接收方决定的
                        发送方也有一个发送缓存,要发送的数据会先放入这个缓存中,然后是在这个缓存中进行滑动窗口
                        接收方的缓存,接收到的数据会放进去
                        建立连接时,接收方就会告诉发送方,接收的滑动窗口有多大
                    SACK(Selective Acknowledgment,选择性确认)
                        概述
                            在TCP通信过程中,如果发送序列中间某个数据包丢失,比如(1,2,3,4,5中的3丢失了)
                            TCP在收到确认后,会进行重传(收到的确认是2,那么对于3,4,5会重新发送)
                            这样原先你已经正常传输的分组也可能会重复发送(比如4,5),虽然说接受的时候会把之前的4,5丢掉,不会影响正确性,但是这样效率很低了,降低了TCP的性能

                            为了概述上述的问题,发展出了SACK(Selective Acknowledgment,选择性确认)
                            
                        作用
                            告诉发送方哪些数据丢失了,哪些数据已经提前收到

                            使得 TCP 重传的时候只会重新发送丢失的包(比如:3),不用发送后续的正常接收到的包(比如:4,5)
                        
                        SACK
                            "SACK信息会放在TCP首部的选项可变部分"
                                接收方进行确认的时候,就会在首部的选项可变部分中说明哪些收到了哪些没收到
                            选项部分(最大40字节)
                                Kind(种类)
                                    占1个字节
                                    如果值为5的话,代表这是个SACK
                                    其他值代表其他类型
                                Length(长度)
                                    占1个字节
                                    表明SACK一共占用了多少字节
                                Left Edge(左边界)+Right Edge(右边界)
                                    都是占4个字节,一对占8个字节,最多就是(40-2)/8=4
                                    最多携带4组边界信息,此时sack最大占用字节数=4*8+2=34字节

                                    还是需要确认号,告诉确认到哪里了
                                        比如说确认号是201,左边界是301,右边界是401,那么就说明201到300这个包没收到,但是301~401收到了...
                                        以此类推
                                    这样就知道哪些收到了哪些没收到
                    
                    注意
                        建立连接的时候都是三次TCP,然后连接建立好之后,开始通信的时候,该用啥就用啥,比如HTTP
                        在传输层就已经分包了,然后这些分包分了之后,加上传输层的首部,然后再传递给网络层,网络层再加上网络层的首部,再传递给数据链路层,数据链路层再加上首部+尾部(FCS...),然后传递给物理层传输
                            基本上传输层就已经拆的很小了,网络层就不咋拆了

                        至于一口气能发几个包,取决于接收方的窗口大小
                    问题
                        1. 如果某个包在重传了N次之后还是失败,会一直持续重传到成功吗?
                            取决于操作系统的设置,超过一定的重传次数/时间,还未收到来自对方的确认报文,于是发送reset报文⭐️
                                有的系统,重传了5次还没成功,就会发送reset报文(RST=1)断开TCP连接
                        2. 接收方缓存不够用了怎么办?
                            接收方有个缓存嘛,那传输的时候发现缓存不够用了咋办,这个时候就会告诉发送方,接受窗口大小大概还能放多大
                        3. 传输的数据总大小小于窗口大小怎么办?
                            假如我的窗口是400,那发送方发过来的数据实际上总大小可能只要200+,没有400,那接收方如何确定后面还有没有包呢?
                             他会等一段时间,然后看看是否还有后面的包,如果没有,就会进行回复确认200+给发送方
                        4. 为什么选择在传输层就将数据"大卸八块"分成多个段,而不是等到网络层再分片传递给数据链路层?
                            一般都轮不到网络层去拆数据
                            概述
                                网络层+数据链路层无法实现"可靠传输"啊
                                    网络层分片之后,走到数据链路层,然后数据链路层的这些帧去传输的时候,到路由器可能会被丢掉哦,比如说像ICMP第一次会就会被丢掉,网络拥堵的时候也会丢数据,那数据丢了咋整,网络层他也没有"可靠传输"啊,他也不会对这些丢掉的小部分数据进行重传,数据链路层+网络层都"没有重传的功能"
                                        然后不完整的数据给到对面传输层,它也不能拼出一个完整的数据,然后就觉得数据不完整,依据可靠传输的特点,他不会回复确认ack,然后源传输层就会认为超时了,它没收到ack嘛,于是"全部数据重发","而不是只重发丢失的数据"
                                只有传输层才有可靠传输的功能
                                    网络层和数据链路层都只是负责,数据过来,然后加个首部/首部尾部,然后往下走

                                ack确认是传输层给传输层的,那源传输层就知道对方传输层收到了数据
                                什么超时重传啊,确认丢失啊,都是传输层的

                                如果没有传输层,那就是没有可靠传输了,那数据丢了就丢了
                            总结
                                1. 可以提高重传的性能
                                    如果给到网络层分片,那数据丢失就得全部重传了,而不是选择性重传
                                    传输层分片,对方就可以根据特性/首部sack啊,知道哪个包丢了,然后只传对应丢失的包就可以了
                                2. 如果在传输层分段,一旦数据丢失,只需要重传丢失的段即可⭐️
                                    如果不在传输层进行分块,而是一整块给网络层,那么如果传输中有数据丢失,网络层只会告诉传输层说,哦你这一大块数据中有的数据丢了,传输层又不知道到底哪部分数据丢了,然后呢网络层又没有重传的功能,这个时候只能是传输层去重传,将一整块数据又再次重传,那sack啥的就没用上啊

                                主要还是提高重传的性能吧,因为就算传输层不分段,那数据还是可以去到对面,丢失了的话,那还是可以重传过去,只不过是将全部数据都重传过去,因为对传输层而言,就是一个很大的包

                                
                            
                    如果应用层还有个很大的文件需要传输,那么在传输层就分成了很多个段,每个段差不多就"1400多字节",然后网络层就用不着分片,因为这样即使传到数据链路层,MTU也不会超过1500字节
                        传输层切成多少个块,网络层就有多少个包,数据链路层就有多少个帧
                "流量控制"
                    TCP建立连接之后,接收方就会告诉发送方"接收窗口大小"(这个是动态变化的,不是定死的),接收窗口大小跟缓存有关

                    问题
                        如果接收方的缓存区满了,发送方还在疯狂地发数据
                            那接收方只好把收到的数据包丢掉(属实处理不过来了),大量的丢包会极大地浪费网络资源

                            所以就需要进行流量控制,就是根据缓存区的大小,决定让发送方发送多少数据,而不是疯狂地漫无目的地发送
                    概述
                        根据缓存区的大小,决定让发送方发送多少数据,而不是疯狂地漫无目的地发送
                        让发送方的发送速率不要太快,让接收方来得及接收处理
                    原理
                        通过"确认报文首部"中的"窗口字段"来控制发送方的发送速率
                            接受方每次确认的时候都会告诉发送方窗口大小有多大⭐️
                        发送方的发送窗口大小不能超过接收方给出的窗口大小

                        发送方的发送窗口
                            就是实际发过去的大小
                        接收方的接收窗口
                            限定了能接受多少
                        只有当发送方的发送窗口<接收方的接收窗口时,才会进行发送,然后如果收到确认之后,发送方窗口会滑动

                        当发送方接收到窗口的大小为0的时候后(说明缓冲区已经满了),发送方就会停止发送数据

                        就是接收数据吗? 接收的话,那肯定也有个度啊,不可能让你随便发,要在我处理的过来的范围内嘛,就是两边的一个约定,而这个约定就是TCP首部中的"窗口"
                    特殊情况
                        描述
                            一开始,接收方给发送方发送了0窗口的报文段
                            后面,接收方又有了一些存储空间,给发送方发送的非0窗口的报文段丢失了

                            那么这样就会导致双方的发送窗口一直为0,双方陷入僵局
                        解决方案
                            当发送方收到0窗口通知时,这时发送方停止发送报文
                            并且同时开启一个定时器,隔一段时间就发送一个测试报文去询问接收方最新的窗口大小
                            如果接收到的窗口还是0,则发送方再次"刷新启动定时器",然后还是依次循环
                "拥塞控制"(全局)---希望适量发少一点
                    吞吐量
                        单位时间内"成功"地传送数据的数量(以比特、字节、分组等测量)
                    带宽
                        用来标识信号传输的数据传输能力,标识单位时间内通过链路的数据量
                    实际上带宽达到轻度拥塞的时候,就开始丢包了,如果拥塞再增大,那吞吐量就可能会下降,甚至导致死锁
                        就像是开车,理论同时开1000辆,但是实际可能几百两就有点堵了,因为前面的传输速率不保证
                    作用
                        "防止过多的数据注入到网络中"
                        避免网络中的路由器或链路过载

                        拥塞控制是一个"全局性"的过程,涉及到主机,路由器,以及与降低网络传输性能有关的所有因素,是大家共同努力的结果
                            "流量控制"是"点对点","端对端"的,接收方对发送方这种两端之间
                            而拥塞控制是全局的,仅仅能靠几个设备就能拥塞控制吗? 那显然不可能
                        
                        控制整个网络不要这么拥堵
                    每一层的数据大小范围
                        一般数据链路层的MTU最大为1500,那么到网络层,网络首部+网路数据<=1500,网络首部一般是20字节,所以网络层数据部分最大为1480,到了传输层,传输层首部+传输层数据部分<=1480, 传输层首部最小为20字节,所以传输层数据部分最大为1460字节
                    几个缩写
                        MSS(Maximum Segment Size)
                            传输层在分段之后,每个段最大的数据部分大小
                            在建立连接时确定段的大小(不一定是1460)
                                建立连接: 互相交换一些信息,SYN,(SYN,ACK)的时候就会带上MSS等信息(第一次+第二次)

                                连接的时候,首部是32字节,不是20字节,第一次和第二次握手(SYN,SYN+ACK),第三次是20字节
                                那很明显,多出来的12字节是在"可选区域"的,那存的是啥呢? 是不是就是MSS这些信息,总共6个字段,每个两个字节
                                    MSS(不一定是1460),NOP(No-Operation),Window Scale,NOP,NOP,SACK permitted

                                诶可能第一次从服务端发过来的MSS是1460,但是SYN,ACK的时候回给服务器的MSS是1412,那取谁呢? "取最小值"
                                这个就叫协商,就是你给个你那边的最大值,我这边给我允许的最大值,那这样最终取最小的嘛,就叫做协商
                            
                        cwnd(congestion window)---拥塞窗口大小
                            在"发送方"
                            发送方发现啊,现在网络比较拥堵,不能发5k,只能发个3k左右,那这个时候拥塞窗口大小就是3k
                            如果网络情况很顺畅,那拥塞窗口可能变成8k,但是接收方的接收窗口只有5k,所以最终实际发送的swnd还是5k

                            "发送方自己进行调整的",去感知网络情况
                        rwnd(receive window)---接收窗口大小
                            "接收方"告诉发送方,能接受的"总数据量"是多少
                            比如接收窗口大小是5k,那如果一个包的大小是1k,那下一次最多发5k的数据,也就是5个包过来
                        swnd(send window)---实际发送窗口大小 
                            "发送方"中实际发送的窗口大小,比如这一次实际发送了5k,那swnd就是5k

                            swnd=min(cwnd,rwnd)

                    拥塞控制方法
                        慢开始/慢启动(slow start)
                            概述
                                就是刚开始发慢一点,然后逐渐加快速度dadada
                            举个例子
                                比如说建立连接的时候,接收方告诉发送方,MSS=100,rwnd=3000,啥意思呢? 
                                    就是诶,每个最大的段是100字节,接收窗口的大小是3000字节,那也就是说我一次性最多可以接受3000/100=30个包
                                但是慢启动是,刚开始并不会发30个包,而是慢慢一点一点来,先发一个包,cwnd(拥塞窗口为100),收到确认之后,cwnd再扩大,比如扩大到之前的两倍200,然后发两个包,再收到确认之后,cwnd再扩大,发四个包... 依次类推,最终拥塞窗口的大小会变成接收窗口的大小


                                所以说下载速度由慢变快,然后稳定一个值是这样的吗
                            总结
                                cwnd初始值会比较小,随着数据包被接收方确认(收到ACK),cwnd就成倍增长(指数级)
                        拥塞避免(congestion avoidance)
                            
                            ssthresh(slow start threshold)
                                "慢开始阈值",就是cwnd(阻塞窗口的大小)达到某一个阈值之后,就不是再以指数级增长了,而是以"线性方式"增加
                            拥塞避免
                                在慢开始的基础上,"拥塞窗口"缓慢线性增大,以防止网络过早出现拥塞
                            乘法减小
                                只要"网络出现拥塞",把"ssthresh减半",与此同时,执行"慢开始"算法("cwnd又恢复初始值")
                                    cwnd(拥塞窗口大小)恢复成初始值之后呢,又是指数级增长,只不过这个时候ssthresh已经变成原来的一半了(新阈值,拥塞窗口峰值减半),走到这里的时候的时候就变成"线性增长"


                                它怎么判断如何出现网络拥塞呢? 
                                    是看丢不丢包,如果发生了丢包,那说明网络拥塞了,因为正常不拥塞的情况下是不会产生丢包的
                                网络出现频繁拥塞的时候,ssthresh就会下降的很快

                                丢包和丢段的说法不纠结哈
                        快速重传(fast retransmit)
                            概述
                                以前一直都是超时重传,只有超时了才会进行重传,快重传相当于是"催人家",重要的事情说三遍

                                快速重传和超时重传是同时存在的
                            接收方 
                                每收到一个"失序"的分组/包/段后,就立即发出重复确认,使发送方及时知道有分组没有达到
                                "不要等待接收方自己发送数据时才进行确认"
                                    以前是sack,接收方凑齐了M1,M2,M4之后,发现M3没了,然后才告诉发送方M3丢了,不是一碰到M3丢了就告诉发送方,现在是一碰到M3丢了就告诉发送方,进行快重传
                            发送方 
                                只要连续收到三个重复确认(总共是4个,加上上一次的确认),就应当立即重传对方尚未收到的报文段
                                不必继续等待重传计时器到期后/接收方发送sack再重传


                            举个例子
                                比如现在A要给B批量发送M1...M4,前两个M1,M2都正常发送过去了,B也收到并确认了,但是M3在发送的途中丢了,丢包了,那咋整,然后M3丢了,M4发过来了,按照以前的方式,M3丢失了确认的时候才会进行重传,那就很慢嘛,所以我就让他快速重传,怎么快速重传呢?
                                    当B收到M4的时候,我就给A回复三个M2的确认(里面ack就是让A发送M3过来),那A连续收到3个M2的重复确认之后,就知道,奥M3丢了,那这个时候就立即给B发送一次M3,这样速度不就上来了吗,不用等到我非得拿到你所有的一次性批量发过来的包之后,
                            
                            就是现在接收方一碰到"失序"的数据,就立马让发送方快速重传,而不是说我硬要等到非得拿到一次性批量发过来的包之后才回复确认比如说M3丢了,这样效率就提升了
                                比如我一次性发了10个包,而第二个包丢了,那以前的sack什么时候让发送方重传呢? 愣是要等到收到后面的8个包之后才会确认让发送方重传,是不是就要等啊? 那就很慢了嘛,我一发现就让他重传嘛,那不快得多?
                        快速恢复(fast recovery)---拥塞避免的升级
                            快重传+快恢复

                            发现丢包,怎么发现丢包的呢? 
                                只要接收方返回三个确认,就说明丢包了要快速重传,然后一丢包,说明就发生了拥塞,发生拥塞,ssthresh就减半,上面的"拥塞避免"(慢开始:cwnd回到初始值,然后指数级,线性增长)过时了,不用了

                            现在是cwnd不从"初始值"开始了,而是"从新的阈值开始"☆☆☆
                                要是从"初始值"开始的话,那速度就会很慢嘛,那就不执行"慢开始"算法,直接取新阈值的值,速度提高
                            
                            船新版本

                            概述
                                当发送方收到三个重复确认(开始丢包,发生拥塞),就执行"乘法减小"算法,将ssthresh减半
                                与慢开始不同之处是现在不执行慢开始算法,即cwnd现在不恢复初始值
                                而是把cwnd值设置为ssthresh减半后的数值
                                然后开始执行拥塞避免算法("加法增大"),使得拥塞窗口缓慢线性增大
                        发送窗口最大值
                            swnd=min(cwnd,rwnd)
                            发送窗口最大值=min(拥塞窗口,接收窗口)

                            rwnd<cwnd(接受窗口<拥塞窗口)
                                "接收方的接收能力"限制发送窗口的最大值
                            cwnd<rwnd(拥塞窗口<接收窗口)
                                "网络的拥塞"限制了发送窗口的最大值
                            
                            滑动窗口
                "连接管理"(三次握手,四次挥手)
                    序号(sequence number)
                        作用
                            就是告诉对方当前发送的数据,第一个字节的编号,就是告诉人家从哪里开始发送的
                            一般看到的是相对值,就是在本次传输中的相对序号
                        TCP首部中存储的序号
                            TCP首部中存储的序号,占32位,4个字节,那肯定不是简单的"相对序号",存储的实际上是"真实序号值"(raw)
                            安全性问题
                                如果将简单的相对序号存放在TCP首部中,那么也会有安全性问题⭐️,拿到这个简单的相对序号,再拿着其他的数据算一下,就可以算出来,然后模拟下一次数据包的发送,那就很不安全了
                            那么这个raw值是怎么来的呢?
                                是在建立连接的时候来的,发送方和接收方是相对的,相对而言,谁在发数据谁就是发送方
                                当第一次握手时,客户端会向服务端发送SYN=1,ACK=0
                                    同时他也会加上"客户端的序号初始值"(随机生成),确定自己用什么序号
                                第二次握手时,服务端向客户端发送SYN=1,ACK=1
                                    同时服务端也会带上"服务端的序号初始值",确定自己用什么序号
                                双方都是在建立连接的时候,确定以后自己要用什么序号(真正序号)
                                以后进行通信的时候,真正序号: 当前序号+相对序号
                                    比如说第一次客户端向服务器发请求,那客户端的初始真正信号是:123456,那么此时的请求中带过去的真正信号是123456+1, 因为+1,加上相对序号,第二次呢,那就是12345+1+100,比如一次包的大小是100,像1+100就是相对序号

                                    服务端第一次跟客户端通信的时候,比如服务端的初始序号是234567,那么第一次序号就是234567+1,第二次序号就是234567+1+100... (1+100)就是相对序号 

                                总之,每次服务端和客户端的通信,真实序号都是"在初始值的基础上,加上相对序号"
                                    序号是在自己的基础上,确认号是在对方序号的基础上

                                    "客户端"的初始序号用在
                                        "将来客户端的序号"和"服务端的确认号"中
                                    "服务端"的初始序号用在
                                        "将来服务端的序号"和"客户端的确认号"中
                    确认号
                        作用
                            就是告诉对方下次应该从哪里开始发送
                        真正的确认号ack也是"真正的序号"+数据长度

                    "建立连接的时候只会生成序号啊,确认号是需要用到序号和长度来进行计算出来的"⭐️
                    就是SYN=1的时候确定序号和ack的
                        
                    序号+确认号 过程
                        
                        1. 客户端向服务端建立连接(数据为0)
                            SYN=1,ACK=0     seq     ack 
                            原生             s1      0
                            相对             0       0
                            
                            建立连接的时候,TCP的数据部分为空,所以相对的seq和ack都是0
                                相对序号嘛,表示当前要发送的数据从多少字节开始, 期望下一次的ack是多少嘛(也没啥要确认的),当前只是建立连接,根本就不会有数据,所以相对seq和ack都是0
                        2. 服务器同意与客户端建立连接(数据为0)
                            SYN=1,ACK=1     seq     ack 
                            原生            "s2"    s1+1
                            相对             0       1

                            ack为s1+1,希望下一次客户端发数据的时候是从(s1+1)开始发,此时数据长度也是为0
                        3. 客户端回应服务端的同意(数据为0)---此时虽然相对序号从1开始了,但是数据仍然是0,没有发送任何数据
                            SYN=0,ACK=1     seq     ack 
                            原生            s1+1    s2+1
                            相对             1       1

                            "相对序号"=1,"相对确认号"=1

                            就是对 2 进行回应(2里面的ack是1嘛,希望客户端下一次发送序号为1的嘛),把他看作是第一次发请求吧,但是没数据

                        4. 连接建立之后,客户端向服务端发送"HTTP请求"---跟 3 一样,只不过有数据了,假如数据占K字节
                            这个时候TCP就有数据了,数据是来自HTTP协议的数据
                            SYN=0,ACK=1     seq     ack 
                            原生            s1+1    s2+1
                            相对             1       1

                            只有1,2步的SYN=1, SYN=1代表建立连接,区别就是看ACK是否=0,=0,代表客户端建立连接,=1,代表服务端同意建立连接
                        5. 服务端返回三个数据包
                            服务端返回数据给客户端---数据b1字节
                                SYN=0,ACK=1     seq     ack 
                                原生            s2+1    s1+k+1
                                相对             1       k+1
                            服务端返回数据给客户端---数据b2字节
                                SYN=0,ACK=1     seq     ack 
                                原生           s2+b1+1  s1+k+1
                                相对            b1+1     k+1
                            服务端返回数据给客户端---数据b3字节
                                SYN=0,ACK=1     seq         ack 
                                原生           s2+b1+b2+1  s1+k+1
                                相对            b1+b2+1     k+1
                        为啥服务器返回数据的时候ack都是k+1呢?
                            因为客户端就只向服务器发了一次数据(k字节),然后呢,服务端返回的ack又是期望下一次客户端发送的序号,人家就发了一次嘛,那肯定就是k+1,又不像你服务器一下子就发了四次,那肯定每次都要变化
                        6. 客户端收到来自服务器的三个包之后,进行确认---TCP数据部分为0,这个只是个确认嘛
                            SYN=0,ACK=1     seq         ack 
                            原生            s1+k        s2+b1+b2+b3+1
                            相对            k+1         b1+b2+b3+1

                        凡是进行"确认"的,"TCP数据部分都是0"
                    建立连接(三次握手)
                        第一次,客户端请求服务器建立连接
                            SYN=1,ACK=0
                            概述
                                
                        第二次,服务端同意与客户端建立连接
                            SYN=1,ACK=1
                        第三次,客户端对服务端的同意进行回应
                            SYN=0,ACK=1
                            注意啊,这个时候SYN=0
                            第三次就相当于是对前两次握手的一个最终确认,告诉服务器我要真正开始发数据过来了

                        连接建立好之后就是正式发送数据... 然后服务器返回数据给客户端,那可能返回的数据很大,就采用连续ARQ传一批数据回来,然后客户端确认一下(首部带上ACK(期望下一次从什么序号开始传)),然后服务端又继续传数据回来,数据传完之后,服务端返回个HTTP 200

                        建立的流程
                            刚开始还没建立连接,那么客户端处于关闭状态,服务器处于"监听"状态
                            第一次握手
                                当客户端发送一个建立连接的请求(SYN=1,ACK=0,seq=x),然后客户端处于 "SYN-SENT"(同步已发送)的状态,一旦客户端处于SYN-SENT状态,就说明第一次握手已经出去了
                            第二次握手 
                                当服务端接收到客户端发来的建立连接的请求时,觉得没有毛病,"同意连接",就回复客户端一个响应(SYN=1,ACK=1,seq=y,ack=x+1),处于 "SYN-RECVD"(同步已接收)
                            第三次握手
                                客户端再给回一个ACK确认(SYN=0,ACK=1,seq=x+1,ack=y+1),然后他就认为连接已经建立,当服务端也收到这个确认时,连接已经建立

                                第三次就相当于是对前两次握手的一个最终确认,告诉服务器我要真正开始发数据过来了

                            接着就是互传数据了
                        状态解读
                            CLOSED: client处于关闭状态
                            LISTEN: server处于监听状态,等待client连接
                            SYN-SENT: 表示client已发送SYN报文,等待server的第二次握手
                            SYN-RECVD: 表示server收到了建立连接的SYN报文,当收到client的ACK报文后,server就会进入 "ESTABLISHED" 状态
                            ESTABLISHED: 表示client和server之间的连接已经建立,三次握手后,客户端和服务端都会进入这个状态,服务器就一直等客户端发数据过来
                        前两次握手的特点
                            SYN都是1
                            数据部分的长度都为0,第三次也是为0
                                只要是在建立连接的状态,数据部分的长度都为0 
                            TCP头部的长度一般是 32 字节(20+12)---用来交换信息
                                固定首部(20)
                                选项部分
                                    MSS(不一定是1460)
                                    NOP(No-Operation)
                                    Window Scale(window 缩放值)
                                        假如是7,那么就要*128,假如是8,就要*256

                                        首部中有个窗口大小,这个窗口的大小*缩放值--->实际的窗口大小
                                        客户端接收数据的时候会告诉服务端窗口是多大,那么通过给到的这个窗口值*缩放值,就是实际窗口可以接受的容量
                                            因为毕竟窗口就是16bit,两个字节,有的时候存不下那么大的值,所以需要进行缩放来存储

                                        缩放值相当于是一个拿来"算窗口大小"的
                                    NOP,NOP
                                    SACK permitted
                                        允许SACK
                                主要是交换一些比如 "MSS","窗口缩放系数"啊,是否"允许SACK"啊...
                                MSS和SACK都存在首部并不会引起冲突
                                    MSS只发生在第一次和第二次握手时,而SACK是发生在数据确认时
                        为什么建立连接需要3次握手? 两次不行吗?
                            主要目的
                                防止server端一直等待,浪费资源
                            第三次的作用
                                第三次就相当于是对前两次握手的一个最终确认,告诉服务器我要真正开始发数据过来了

                            如果建立连接只需要两次握手,可能会出现的情况/问题
                                当client发出的第一个连接请求报文,因为网络超时,在连接释放之后才到达server
                                    两次握手
                                        如果只采用两次握手,那么如果第一次握手网络超时,然后client就会重新发送建立连接的请求,重新建立连接,然后一顿blabla数据发送,关闭连接
                                        但是连接关闭了之后,诶致之前第一次超时的连接请求到达了服务器,然后服务器就同意给客户端进行连接,返回一个ACK,然后它就在那一直等client给他发数据,等啊等啊等,但是client呢? 收到server发来的同意连接ACK之后,由于这个连接都已经断开释放了,数据也都发完了,自然是不可能再给server发数据的,可是"server就在那等等等",浪费资源

                                        具体等多久呢? 看具体设置,可以等很久很久


                                    而如果使用三次握手,就可以解决这样的问题
                                        就算超时,连接关闭,服务器回给client一个ACK,但是没有等啊,要等到client的第三次握手(相当于是确认)过来之后,服务器才开始等,这个第三次就"相当于告诉服务器啥时候开始等我的数据",那ACK发给client了,发了就发了,人家接收之后不处理,我也不等待,那就不会产生什么影响
                                        
                                        服务端就一定得等到第三次握手之后才会进行等待
                        第三次握手失败怎么办呢?
                            当进行第三次握手的时候,说明服务器已经进入了SYN-RECVD状态,如果等不到client的第三次ACK,"server就会重发SYN+ACK包"(一定得等到第三次握手⭐️)

                            如果server多次重发SYN+ACK包都等不到client的第三次ACK,server就会发送"RST"报,"强制关闭连接"

                    释放连接(四次挥手)
                        状态说明
                            ESTABLISHED: 连接已经建立的状态
                            FIN-WAIT-1
                                表示想主动关闭连接
                                eg
                                    客户端发起FIN请求,那么客户端就会进入FIN-WAIT-1状态

                                如果在此状态下,收到了对方同时带FIN标志+ACK标志的报文,可以直接进入TIME-WAIT状态,无需经过FIN-WAIT-2状态
                            CLOSE-WAIT
                                表示在等待关闭
                                当对方发送FIN给自己,自己会回应一个ACK报文给对方,此时则进入到CLOSE-WAIT状态
                                eg 
                                    客户端发送了FIN请求,然后服务器就会进入CLOSE-WAIT状态
                                在此状态下,需要考虑自己是否还有数据要发送给对方,"如果没有,则发送FIN报文给对方"
                            FIN-WAIT-2
                                只要对方发送了ACK确认,主动方就进入FIN-WAIT-2状态,然后等待对方发送FIN确认报文
                            LAST-ACK
                                被动关闭的一方(eg:服务器)在发送FIN报文后,最后"等待对方的ACK报文" 第三次挥手
                            TIME-WAIT
                                主动方已经收到了被动方的FIN报文,并且发送出了ACK报文,就等2MSL后即可进入CLOSED状态了

                                过了TIME-WAIT之后才会进入到CLOSED
                            CLOSING(比较罕见)
                                发了FIN报文后,没有收到对方的ACK,而是收到了对方的FIN,异常
                                如果双方几乎在同时准备关闭连接的话,那么就出现了双方同时发送FIN报文的情况,也即会出现CLOSING状态

                                就是双方几乎同时准备关闭连接,同时分手



                        大致流程
                            1. 客户端向服务器发送"释放连接请求"
                                FIN=1,ACK=1,seq=u,ack=v
                                告诉服务器,客户端已经没有数据可以发送了,但是此时客户端还是可以接受服务器来的数据
                                只是代表客户端将来不会发数据给服务器了
                                此时服务器还是可以给客户端发数据
                            2. 服务端"确认收到"释放连接请求
                                ACK=1,seq=v,ack=u+1
                                这个时候只是表明服务端知道客户端没有数据要进行发送了,但是此时服务器还是可以发送数据到客户端的(可能有一部分数据没处理完)

                                而且发送数据到客户端,客户端也是可以进行ACK的
                            3. 服务端向客户端发送"释放连接请求"
                                FIN=1,ACK=1,seq=w,ack=u+1
                                这个时候服务器数据处理完了,也没有数据要发送的了,然后告诉客户端,可以真正断开了
                            4. 客户端进行确认
                                ACK=1,seq=u+1,ack=w+1
                                表示客户端知道服务端没有数据要进行发送了.随后就正式断开TCP连接
                                服务端收到这个确认之后,也就知道客户端知道了,也就会正式断开,如果服务端没收到这个ACK,那就不会释放连接
                        细节(TIME-WAIT等待2MSL)
                            TCP/IP协议在设计上,"允许任何一方先发起断开请求"
                            主动方在发送最后一次挥手的时候(TIME-WAIT),会等待个2MSL才会真正关闭连接
                                MSL(Maximum Segment Lifetime,最大分段生存期)---容错时间
                                    代表"TCP报文在Internet上的最长生存时间"
                                        不管你路程有多远,中国往美国传,两分钟到了就GG
                                    每个具体的TCP实现(比如说操作系统)都必须选择一个确定的MSL值,RFC 1122建议是"2分钟"
                                
                                为啥要等 2MSL 这么个时间?
                                    如果client发送了最后一次握手ack后马上就将连接释放了,然后因为网络原因,对方server又没有收到client的ACK,那么"server就会重新发送FIN"

                                    但是发现,诶我靠你一下子连接都关闭了,连接都没了,那不GG了,可能产生如下情况
                                        1. 这个时候收不到client的ACK,服务器就会干等,甚至多次重发FIN,浪费资源
                                        2. client有个新的应用程序刚好分配了同一个端口号,新的应用程序收到FIN之后马上开始执行断开连接的操作,本来它可能是想跟server建立连接的

                                    就是给个容错时间,防止网络波动啊,断开等情况产生,关闭也没说一定得多及时,要立马关闭
                                    用来等待服务器的FIN,防止服务器浪费资源(一致发FIN)/防止FIN发送给新的程序

                                    "防止本次连接的FIN发送给新的程序",因为本次连接的数据包都会在2MSL时间内消失/失效
                                        就是让上次连接的数据包失效,一个MSL就失效了嘛,等两个MSL必然失效


                            自己发给自己,是不走网卡的,那也就是抓包工具正常情况抓不到(它默认抓网卡),而要抓loopback(环回)

                            发送链接关闭都是 FIN=1,ACK=1,确认关闭都是ACK=1
                        客户端跟服务端保持的是"长连接",只要不关闭,一直保持连接状态

                        默认情况
                            假如(建立连接后)中途网络真的GG了,那服务器会一直等待,耗费资源

                            
                        平常真实开发情况(要节省资源)
                            可能服务器在一段时间内没有收到数据包,那么他就会把这个"连接给主动断掉",以节省资源

                            为了"保活",客户端会隔一段时间给服务器发送一个数据包,让他不要断开连接,"心跳包"

                            当然,传输层也是有这种策略的,但是呢一般不用,一般貌似在应用层控制
                        有的时候抓包工具可能只会看到"三次挥手"
                            实际上是服务器将第2,3次挥手进行合并了
                            
                            发生的时机
                                当server接收到client的FIN时,如果server后面也没有数据要发送给client了,就可以将2,3次挥手合并,同时告诉client两件事
                                    1. 已经知道client没有数据要发送了
                                    2. server也没有数据要发送了

                                    客户端状态会从"FIN-WAIT-1"直接进入到"TIME-WAIT",跳过了FIN-WAIT-2
                    问题
                        长连接和短连接是如何区分的?
                            短连接
                                交互一次建立一次连接,关闭连接
                                浪费资源
                            长连接
                                建立一次连接,中间不会断开,可以进行多次数据交互

                                客户端/服务端决定什么时候释放连接,这个不确定额
                        网卡工作在数据链路层
        Socket
            Socket是专门用来网络通信的
                比如一个客户端就是一个Socket对象,java中服务端是一个ServerSocket,而ServerSocket又会产生很多个Socket来跟连接到他的客户端Socket进行通信,客户端与服务端之间的Socket通信是相互独立的,互不影响
        
        应用层☆☆☆
            常见协议
                超文本传输协议
                    HTTP,HTTPS
                文件传输
                    FTP
                电子邮件
                    SMTP,POP3,IMAP
                动态主机配置
                    DHCP
                域名系统(Domain Name System)
                    DNS
            域名(Domain Name)
                概述
                    如果ip地址不方便记忆,并且不能表达组织的命好吃呢个性质,所以设计出了域名
                    最终域名还是要解析成IP地址
                为什么不直接使用域名而是使用IP呢?
                    IP占4个字节,域名不确定要占多少字节,一个英文字母一个字节,无疑增加了路由器的负担,浪费"流量"
                域名分类
                    顶级域名,二级域名,三级域名...
                    通用顶级域名(gTLD)
                        .com (公司) .net(网络机构) .org(开源组织) .edu(教育) .gov(政府部门) .int(国际组织) ...
                    国家及地区顶级域名(ccTLD)
                        .cn(中国) .jp(日本) .uk(英国)
                    新通用顶级域名
                        .vip .xyz .top .club .shop
                二级域名
                    顶级域名之下的域名
                    通用顶级域名下的
                        一般指域名注册人的名称
                            google microsoft baidu

                            baidu.com  baidu是二级域名 .com是顶级域名 两个合起来baidu.com
                    国家及地区顶级域名下的
                        一般指注册类别
                            xxx.gov.cn xxx.com.cn xxx.edu.cn
            DNS
                利用DNS协议,可以将域名(baidu.com)解析成对应的IP地址
                    计算机在请求域名之前,会先发送DNS协议(基于TCP/UDP)的请求,请求中带有"域名"信息,回复中带有"IP"信息,去DNS服务器获取对应的IP,DNS服务器存了域名和IP的对应关系,然后拿到之后就会在本地缓存一份,以后就直接走这个缓存就行
                DNS可以基于UDP,也可以基于TCP,不论基于哪种,都会占用"53"端口
                常用命令
                    ipconfig /displaydns
                    ipconfig /flushdns
                    nslookup 域名
                        也可以做域名的解析
                DNS服务器
                    客户端首先会访问最近的一台DNS服务器(也就是客户端自己配置的DNS服务器,一般是自动)
                    所有的DNS服务器都记录了 DNS根服务器(.)的IP地址
                    上级DNS服务器记录了下一级DNS服务器的IP地址
                        比如顶级的DNS服务器记录了二级DNS服务器的地址
                        . 记录了顶级 DNS 服务器 (.com)的地址,.com又记录了baidu啊之类的地址

                    全球一共"13台IPv4的DNS根域名服务器","25台IPv6的DNS根域名服务器"

                流程
                    比如说找 example.microsoft.com
                    1. 计算机先找到本地名称服务器(离他最近的那一台DNS)
                    2. 本地服务器又去找DNS根服务器
                        根服务器发现我不知道你这个example.microsoft.com,但是我知道 .com , 好于是就回复本地名称服务器,让去找顶级服务器
                    3. 本地服务器去找顶级服务器
                        顶级服务器只知道.com ,不知道microsoft.com,于是回复本地名称服务器去找二级DNS服务器
                    4. 本地名称服务器去找二级DNS服务器
                    ...
            DHCP
                IP按照分配方式分类
                    静态IP+动态IP
                静态IP
                    手动设置
                    适用场景
                        基本不挪动的台式机(学校的台式机),服务器等 
                动态IP
                    从DHCP服务器自动获取IP地址
                    适用场景
                        移动设备+无线设备...
                概述(动态分配IP)
                    DHCP(Dynamic Host Configuration Protocol)---动态主机配置协议
                    
                    DHCP协议"基于UDP协议",客户端端口68,服务器端口67

                    DHCP服务器会从"IP地址池"中,挑选一个IP地址"出租"给客户端一段时间,"时间到期就回收他们"

                    平常家用路由器就可以充当DHCP路由器 就是路由器分配IP地址嘛
                        所以一般家用电脑使用ipconfig /all显示的DHCP服务器是路由器的网关
                DHCP分配IP地址的4个阶段
                    "DISCOVER"(发现DHCP服务器)
                        发广播
                            源IP: 0.0.0.0
                            目标IP: 255.255.255.255
                            目标MAC: FF:FF:FF:FF:FF:FF
                    "OFFER"(提供租约)
                        服务器返回可以租用的"IP地址",以及"租用期限","子网掩码","网关","DNS"等信息

                        计算机发一个广播出去,"可能有多个服务器提供租约"
                    "REQUEST"(选择IP地址)
                        客户端选择一个OFFER,"发送广播包进行回应"
                    "ACKNOWLEDGE"(确认)
                        被选中的服务器发送ACK数据包给客户端

                        DHCP服务器--ACK-->客户端 
                    至此,IP地址分配完毕

                    刚开始我没有ip地址啊,我肯定要向DHCP服务器要ip啊,然后它从IP地址池中选了一些出来让你挑,挑好了之后然后肯定要"广播"告诉DHCP服务器你要用哪一个嘛,然后它那边收到这个确认之后呢,就告诉客户端说啊我知道你要用这个了,那其他人就用不了你选的这个了
                细节
                    DHCP服务器可以跨网段分配IP地址吗?
                        上面发广播都是在同一个网段,那不同网段之间可以分配吗?
                        可以通过"DHCP中继代理"来实现
                    自动续约
                        客户端会在租期不足的时候,自动向DHCP服务器发送REQUEST信息申请续约

                        客户端自动申请续约
                    常用命令
                        ipconfig /all 
                            可以看到DHCP相关的详细信息,比如租约过期时间啊,DHCP服务器地址...
                        ipconfig /release
                            释放租约,不想租了
                        ipconfig /renew
                            重新申请IP地址,申请续约(延长租期)
            HTTP(Hyper Text Transfer Protocal)---超文本传输协议
                概述
                    是互联网中应用最广泛的应用层协议之一
                    设计HTTP最初的目的: 提供一种"发布和接收HTML页面"的方法,由"URI"来标识具体的资源
                        URI包含URL,URI只是相对来讲唯一,URL是全网唯一
                    后面用HTTP来传递的数据格式"不仅仅是HTML",应用很广泛
                版本
                    HTTP/0.9---1991
                        只支持GET请求方法 获取文本数据(比如HTML),且"不支持请求头,响应头等",无法向服务器传递太多信息
                    HTTP/1.0---1996
                        支持POST,HEAD等更多请求方法,"支持请求头,响应头等",支持更多种数据类型(不再局限于文本数据)

                        注意
                            浏览器的每次请求都需要与服务器建立一个TCP连接,请求处理完之后"立即断开"TCP连接--->短连接
                    HTTP/1.1---1997 最经典,最广泛的版本
                        支持PUT,DELETE等方法
                        支持"长连接"(Connection:keep-alive),多个请求可以共用同一个TCP连接
                            诶一个网页中有很多资源嘛,多次请求嘛,这些可以共用同一个TCP连接,不那么耗费资源

                    HTTP/2.0---2015   基本上已经可以取代1.1了
                    HTTP/3.0---2018
                标准
                    规定了HTTP数据格式,要不然发个HTTP协议的请求过去,人家咋知道怎么解析
                    由万维网协会(W3C),互联网工程任务组(IETF)协调制定,最终发布了一系列的RFC
                    RFC(Request For Comments,请求意见稿)
                报文格式
                    请求报文
                        请求首行(方法 URI 版本)
                        请求头
                            key:value
                            key:value
                            key:value

                        请求体

                        "get请求没有请求体"
                    响应报文
                        响应/状态首行(版本 状态码 短语)
                        响应头
                            key:value
                            key:value
                            key:value

                        响应体
                ABNF(Augmented BNF)
                    是BNF的增强版
                    BNF
                        用作internet中通信协议的定义语言
                    ABNF是最严谨的HTTP报文格式描述形式,脱离ABNF谈论HTTP报文格式都是不严谨的

                    ABNF表示法
                        HTTP-message= start-line *(header-field CRLF) CRLF [message-body]
                        start-line=request-line/status-line (响应)
                            start-line内部自带一个换行
                            request-line=method request-target HTTP-version CRLF
                                GET /hello/login.html HTTP/1.1
                            HTTP-version: HTTP-name "/" DIGIT"."DIGIT
                            HTTP-name: HTTP
                            ; 注释
                        status-line=HTTP-version status-code reason-phrase
                            status-line内部自带一个换行
                            status-code= 3 DIGIT  三个数字
                            reason-phrase=*(HTAB/SP/"VCHAR"/obs-text)
                            
                            HTTP/1.1 200 OK
                        header-field(不包含CRLF换行哈)
                            header-file=field-name":"OWS field-value OWS
                            OWS=*(SP/HTAB)
                        message-body =*OCTET(8位数据)
                            一个OCTET就是一个字节

                        就是上面的格式(请求首行,请求头,换行,请求体)
                            * 代表0个或者多个
                            CRLF 代表互联网标准"换行"
                URL
                    URL 中一旦出现特殊字符(中文/空格),需要进行"编码"
                    浏览器地址栏输入URL时,采用的是"UTF-8"编码
                HTTP服务器(eg:Tomcat)肯定要遵守RFC文档的规范并且要解析对应的HTTP报文,要去实现这个解析
                    也可以增加一下容错性,不是那么遵循RFC规范,也可以解析成功
                请求方法(9个)
                    GET,HEAD,POST,PUT,DELETE,CONNECT,OPTIONS,TRACE,PATCH

                    "GET"
                        常用语读取操作,请求参数直接拼接在URL的后面(浏览器/服务器对URL的长度是有限制的,255字节最长)
                        而且没有请求体,对于传给服务器的数据被限制在URL的最长长度
                    "POST"
                        常用于添加,修改,删除的操作,请求参数可以放到请求体重(没有大小限制)
                        有请求体,也可以使用URL来进行参数传递
                    HEAD
                        请求得到与GET请求相同的响应,但是没有响应体
                        HEAD嘛,只能得到(响应首行+响应头+空行),没有响应体

                        使用场景
                            
                            下载一个大文件前,先获取其大小,再决定是否要下载,以此可以"节约带宽资源"
                            或者做一些测试之类的,响应头会带一个Content-Length
                    "OPTIONS"
                        用于获取目的资源"所支持的通信选项",比如服务器支持的请求方法
                            OPTIONS * HTTP/1.1
                            服务器会返回一个响应头
                                Allow: GET,HEAD,POST... 支持的请求方法
                    "PUT"
                        用于对已存在的资源进行覆盖/更新
                    "DELETE"
                        删除指定的资源
                    PATCH
                        对资源进行部分修改,如果资源不存在,就会创建新的资源
                    TRACE
                        请求服务器回显其收到的请求信息,主要用于HTTP请求的测试或诊断

                        我发什么东西给你,你还是原封不动地换回给我,用来做测试的,看看数据有没有变啊之类的,网络情况咋样啊
                    CONNECT(跟安全有关,HTTPS之类的...)
                        可以"开启"一个客户端与所请求资源之间的"双向沟通的通道",可以用来创建隧道(tunnel)

                        可以用来访问采用了SSL(HTTPS)协议的站点
                头部字段(Header Field)
                    头部字段可以分为4种类型
                        1. 请求头字段
                            有关要获取的资源/客户端本身信息的消息头,"只能用在请求报文中"
                        2. 响应头字段
                            有关响应的"补充信息","只能用在响应报文中"
                                比如服务器本身(名称+版本)的消息头
                        3. 实体头字段
                            有关实体主体的"更多信息",就是用来描述实体(请求体/响应体)的字段
                                比如主体长度(Content-Length)或其MIME类型
                        4. 通用头字段
                            同时适用于请求和响应信息,但与消息主体无关的消息头,"可以同时用在请求报文+响应报文中"

                            Connection: keep-alive
                            Data: xxx
                    请求头字段
                        相当于是跟服务器进行协商,告诉服务器我支持哪些
                        User-Agent 
                            浏览器的身份标识字符串
                                用的什么浏览器啊,版本啊,系统版本啊...

                                比如下载软件的时候默认是下载当前系统对应的版本,就是可以通过这个办到
                        Host
                            服务器的域名,端口号
                            Host: localhost:8080
                        "Date"
                            发送该消息的日期和时间
                        Referer
                            标识浏览器所访问的前一个页面,正式哪个页面上的某个连接将浏览器带到当前页面

                            可以用作"防盗链"
                                有的时候需要限定只能通过上一个页面过来嘛,必须要是在指定的页面进行指定的操作才可以正常给他返回
                                就可以通过Referer进行判断从什么上次页面来的
                        "Content-Type"
                            "请求体"的类型
                                Content-Type: multipart/form-data 
                                文件上传
                            
                        "Content-Length"
                            "请求体"的长度
                                Content-Length: 348
                        
                        Accept
                            能够接受的响应内容类型
                                Accept: text/html,text/plain,applicaiton/xml;q=0.9... 纯文本
                                q是权重值
                        Accept-Charset
                            能够接受的字符集
                                Accept-Charset: utf-8
                        Accept-Encoding
                            能够接受的编码方式列表,压缩
                                Accept-Encoding: gzip,deflate
                        Accept-Language
                            能够接受的响应内容的自然语言列表
                                Accept-Language: en-US 
                        Range
                            "仅请求某个实体的一部分",字节偏移以0开始
                                Range: bytes=500-999
                            跟"断点续传"有关
                                多线程断点下载,每个线程只下载一部分
                                如果断网了,也可以记录每一部分下载到哪里了,实现继续下载
                        Origin
                            发起一个针对跨域资源共享的请求
                                Origin: https://www.baidu.com
                        Cookie
                            之前有服务器通过Set-Cookie发送的Cookie
                                Cookie: xxx=yyy
                        "Connection"
                            该浏览器想要优先使用的"连接类型"
                                Connection: keep-alive 长连接
                                    代表告诉服务器,诶我发送一个请求给你,然后不要断开连接
                        "Cache-Control"
                            用来指定在这次的请求/响应链中的所有缓存机制都必须遵守的指令
                                Cache-Control: no-cache 
                    响应头字段
                        Date
                            发送该消息的日期和时间
                        Last-Modified
                            所请求的对象的"最后修改日期"
                        Server 
                            服务器的名字
                                Server: Apache/2.4.1
                        Expires
                            制定一个时间,超过该时间认为此响应已经过期
                        "Content-Type"
                            响应体的类型
                                Content-Type: text/html;charset=utf-8

                            告诉你我发的是啥,用的啥编码之类的,到时候客户端就是根据对应的类型和编码去进行解析
                        "Content-Encoding"
                            内容所使用的压缩方式
                                Content-Encoding: gzip
                        "Content-Length"
                            响应体的长度(字节为单位)
                                Content-Length: 348
                        Content-Disposition
                            一个可以让客户端下载文件并建议文件名的头部
                                Content-Disposition: attachment;filename="xxx.ext"
                            "文件下载"
                        Accept-Ranges
                            服务器支持哪些种类的部分内容范围
                                Accept-Ranges: bytes
                                说明到时候客户端就可以通过 "Range":bytes 来获取相关数据
                        Content-Range
                            该条部分消息是属于完整消息的哪部分
                                Content-Range: bytes 21010-47021/74022
                        Allow-Control-Allow-Origin
                            指定哪些网站可参与到跨来源资源共享过程中
                                Allow-Control-Allow-Origin: *
                        Location
                            用来进行重定向,或者在创建某个新资源时使用
                                Location: http://xxxx
                        Set-Cookie
                            返回一个cookie让客户端保存
                                Set-Cookie: userid=xxx;
                        "Connection"
                            针对该连接所预期的选项
                                Connection: close
                        "Cache-Control"
                            向从服务器直到客户端在内的所有缓存机制告知,它们是否可以缓存这个对象,单位为"秒"
                                Cache-Control: max-age=3600
                状态码
                    分为5类(常用的)
                        信息响应(100~199)
                            100---Continue
                                请求的"初始部分"已经被服务器收到,并且"没有被服务器拒绝". 客户端"应该继续"发送剩余的请求,如果请求已经完成,就忽略这个响应
                                允许客户端发送带请求体的请求前,"判断服务器是否愿意接受请求"(服务器通过请求头判断)

                                某些情况下,如果服务器在不看请求体就拒绝请求时,客户端再发送请求是不恰当的或低效的

                                先发一个"不带请求体"(因为可能服务器根据URL或者请求头就进行判定不接受的话,带上请求体就相当于浪费资源)的请求,先看一下服务器能不能接受,接受就会返回100,让客户端继续发,不接受不同意那接下来的请求就不发送
                            
                        成功响应(200~299)
                            200---请求成功 OK
                            
                        重定向(300~399) 
                            302---Found
                                请求的资源被暂时移动到了由location头部指定的URL上--->重定向
                            304---Not Modified
                                说明无需再次传输请求的内容,也就是说可以使用缓存的内容

                                是请求到了服务器之后,"服务器判断请求的资源没有发生改变过",所以返回304,告诉客户端直接找缓存吧
                                    返回的数据只有响应行+响应头,没有响应体了
                                    一般静态资源,都会进行缓存

                                    那客户端如果把缓存清除了,那就没办法了,可能涉及到协商缓存+强缓存
                                        请求头中跟缓存相关的
                                            Cache-Control: max-age=xxx
                                            if-Modified-Since: xxx
                                            if-None-Match: xxx
                                        响应头中跟缓存相关的
                                            Last-Modified: xxx --->对应 if-Modified-Since
                                            ETag: xxx   ---> 对应 if-None-Match
                                            
                        客户端错误(400~499)
                            400---Bad Request
                                由于语法无效,"服务器无法理解该请求"⭐️
                                比如: 请求报文的格式不对
                            401---Unauthorized
                                由于缺乏目标资源要求的身份验证凭证
                            403---Forbidden
                                服务端有能力处理这个请求,但是拒绝授权访问
                            404---Not Found
                                客户端请求了一个服务端不存在的资源
                            405---Method Not Allowed
                                服务器"禁止"了使用当前HTTP方法的请求类型,我"可能可以处理",但是我"禁止"了,一个方法规定了用GET但是你要发POST
                                    请求方式错误...
                                    Controller里面某个方法规定用GET,你用了POST请求,405,服务器肯定是支持POST的嘛,只是在这里禁止了POST⭐️
                            406---Not Acceptable
                                服务器端无法提供与Accept-Charset以及Accept-Language指定的值相匹配的响应
                            408---Request Timeout
                                "服务端想要将没有使用的连接关闭"
                                一些服务器会在"空闲连接"上发送此信息,即便是在客户端没有发送任何请求的情况下

                                HTTP/1.1 开始支持长连接嘛,那服务器也可能主动去关闭一些连接
                        服务端错误(500~599)
                            500---Internal Server Error
                                服务器异常,崩了,代码错误
                            501---Not Implemented
                                请求的"方法类型"服务器"不支持",因此无法被处理,直接是不支持,"不是禁止"

                                凡是HTTP服务器,都必须支持GET和HEAD,也就是说GET和HEAD请求永远不会返回 501
                            502---Bad Gateway
                                作为网关/代理角色的服务器,从上游服务器(eg:Tomcat)中接收到的响应是无效的
                            503---Service Unavailable
                                "服务器尚未处于可以接受请求的状态"
                                通常造成这种情况的原因
                                    "服务器停机维护"/"服务器超载"/"服务器正在启动"...
                form表单
                    enctype(请求体的编码方式)
                        application/x-www-form-unlencoded   默认值
                            "请求体"就会按照: 用&分隔参数,用=分隔键和值,字符用"URL编码"方式进行编码
                        multipart/form-data
                            "文件上传"必须使用这种编码方式
                            请求头
                                Content-Type:multipart/form-data;boundary=xxx
                跨域
                    "同源政策"(Same-Origin Policy)
                        默认情况下,"异步请求"只能发送给同源URL
                        "协议"+域名(IP)+"端口" 三个必须要相同,同一个源嘛

                        img,script,link,iframe,video,audio等标签不受同源政策影响
                    解决---实现跨域资源共享
                        需要浏览器客户端+服务器同时支持
                            客户端 
                                所有浏览器都支持(IE至少是10版本)
                            服务器 
                                响应头中设置 Access-Control-Allow-Origin
                                告知浏览器这是一个跨域访问的请求,并且设置允许列表
                                    Access-Control-Allow-Origin: * 表示允许所有源头进行跨域访问
                                    Access-Control-Allow-Origin: localhost:8081
                                
                                浏览器客户端在请求的时候,请求头中也会带上Origin,表明源头是谁
                                    比如前端服务器在: localhost:8081, 那发送请求的时候请求头中就会带上 Origin: localhost:8081
                        实际上浏览器已经接收到了来自服务器的数据,只不过它看,诶你响应头中没有Access-Control-Allow-Origin,那说明不允许跨域访问啊,那自然就不会给到用户显示了
                        服务器加上Access-Control-Allow-Origin这个请求头,"可以控制"谁可以跨域访问我的资源嘛


                        一般是后端解决
                HTTP是"无状态请求"
                    因为它的每个请求都是完全独立的，每个请求包含了处理这个请求所需的完整的数据，发送请求不涉及到状态变更。即使在 HTTP/1.1 上，同一个连接允许传输多个 HTTP 请求的情况下，如果第一个请求出错了，后面的请求一般也能够继续处理（当然，如果导致协议解析失败、消息分片错误之类的自然是要除外的）。可以看出，这种协议的结构是要比有状态的协议更简单的，一般来说实现起来也更简单，不需要使用状态机，一个循环就行了
            代理服务器(Proxy Server)
                概述
                    作为中间代理
                特点
                    本身不生产数据
                        内容都是来自目的服务器
                    处于中间位置转发上下游的请求和响应
                        对于客户端来讲,他是服务器
                        对于服务端来讲,他是客户端
                为啥需要用到代理服务器呢?
                    因为有时候由于某种某种原因,你是找不到目的服务器的,会报一些404,诶,但是能找到代理
                前提条件
                    客户端能访问代理服务器,代理服务器能访问目的服务器
                正向代理+反向代理
                    正向代理
                        代理的对象是客户端
                        作用
                            隐藏客户端身份
                                不再是通过客户端请求目的服务器了嘛,而是通过代理服务器,那肯定就把客户端的信息隐藏了,找一台公网IP的代理服务器
                                服务器一般拿到的是公网IP
                            绕过防火墙(突破访问限制)
                                诶中间有一堵墙,使用代理服务器可以绕过去
                            Internet访问控制
                                使用正向代理,可以控制谁能上网,谁不能上网
                                比如在路由器端,设置A,B,C,D中只有D可以上网,ABC都不可以直接通过路由器上网,那么D就成了代理服务器,ABC要想上网就只能通过D,然后再经过路由器
                                D就可以判断是谁在请求上网,然后看是否能予以通过
                            数据过滤
                                数据过了代理服务器,那肯定可以进行"数据过滤"

                    反向代理
                        代理的对象是服务器
                            到时候"客户端访问代理服务器获取数据"作为服务器,而不是直接访问真正的服务器,由代理服务器来决定是要将请求交给哪台服务器
                        作用
                            隐藏服务器身份
                            安全防护
                                隐藏了真正的服务器嘛,暴露出去的是代理服务器,可以进行"安全防护"
                            负载均衡
                    抓包工具的原理
                        Fiddler,Charles等抓包工具在客户端搞了一个"正向代理服务器",那么服务器过来的数据他就能获取到

                        WireShark的原理是: 通过"底层驱动",拦截网卡流过的数据
                    相关的头部字段
                        Via
                            经过的每一台代理服务器的主机名/域名 
                            
                            Via: proxy1,proxy2...

                            可以放在请求头,也可以放在响应头
                        X-Forwarded-For
                            请求方的IP地址
                            A--->代理--->Server
                            那代理的请求方就是A

                            经过了多层代理的话,那就会进行追加
                                那么第一个IP就是真正的客户端那个IP

                        X-Real-IP
                            真实的客户端IP(某种程度上是客户端路由器的那个公网IP)
            CDN(Content Delivery Network 或 Content Distribution Network)---内容分发网络
                概述
                    利用最靠近每位用户的服务器,更快更可靠地将音乐,图片,视频等资源文件("一般是静态资源")传递给用户
                        以前是所有的用户都到这一台服务器去下载东西,压力很大,主要是距离远一点的话,就会"很慢"
                        使用CDN之后,多台服务器,分布在不同的区域,然后用最近的那一个机房,就很快
                    CDN运营商在全国,乃至全世界的各大枢纽城市都建立了机房
                    部署了大量拥有高存储高带宽的节点,构建了一个跨运营商,跨地域的网络

                    内容所有者(像百度)向CDN运营商支付费用,CDN将其内容交付给最终用户
                使用CDN前
                    客户端先访问DNS服务器,然后DNS服务器根据域名返回IP地址,客户端再去访问服务器
                使用CDN后
                    如果客户端访问的是CDN的资源,那么它先去访问DNS服务器,DNS服务器一看,你这比较特殊,然后呢DNS服务器就会去访问 "CDN DNS服务器",它会返回CND全局负载均衡系统的IP,然后客户端拿到这个CDN负载均衡系统的IP之后就去访问,然后CDN全局负载均衡又会转给CDN区域负载均衡系统,这个区域负载均衡系统就会返回一个离客户端最近的CDN服务器的IP,然后这个时候客户端就可以找到离他最近的CDN服务器了,速度就上来了
                流程
                    用户发起请求,通过智能DNS服务器进行解析(根据用户IP地理位置,接入网络类型,找到离用户路由最短,负载最轻的"缓存服务器"),然后将缓存服务器的IP返回给用户,如果缓存服务器中有目标资源,直接返回,没有的话,就请求源站拿到数据然后将内容保存到缓存服务器,将内容返回给用户

                    当前CDN节点没有就会向上一层节点要,一直找到CDN父层节点,如果CDN父层节点都没有的话,就找源站
            网络安全
                4种安全威胁
                    截获(被动攻击)
                        窃听通信内容
                    中断(主动攻击)
                        中断网络通信
                    篡改(主动攻击)
                        篡改通信内容
                    伪造(主动攻击)
                        伪造通信内容
                ARP欺骗(ARP Spoofing)---ARP病毒/ARP攻击   网络层
                    效果
                        可以让攻击者"获取"局域网上的数据包甚至可以"篡改"数据包
                        可以让网络上特定电脑之间"无法正常通信"
                            eg: 网络执法官这样的软件
                        可以让送至特定IP地址的流量被错误送到攻击者所取代的地方,达到"送错地方"的效果
                    举个例子
                        B通过ARP获取A的MAC地址
                            C是攻击者,A,B是被攻击者
                            C只要收到过A,B发送的ARP请求,就可以拿到AB的IP和MAC地址,从而进行欺骗活动
                            C发送一个ARP响应给B,把响应包中"源IP"设为"A"的IP地址,"源MAC"设置为"C"的MAC地址,这样就可以把存储的A的信息覆盖掉嘛
                            B收到ARP响应后,会更新ARP表,将A的MAC地址(IP_A,MAC_A)改为(IP_A,MAC_C)
                            B要发数据给A的时候,根据ARP表来查,将目标MAC地址设置为MAC_C,而不是MAC_A
                            交换机收到B发送给A的数据包时,根据MAC_C,将数据转给了C,而不是A
                    防护
                        静态ARP
                            ARP 欺骗只是对"动态ARP"有影响(动态获取的嘛),那如果手动指定静态的,就可以进行防护
                        DHCP Snooping
                            网络设备可借由DHCP保留网络上各电脑的MAC地址,在伪造的ARP数据包发出时既可侦测到
                        利用一些软件监听ARP的不正常变动
                DoS+DDoS
                    DoS(Denial-of-Service attack, 拒绝服务攻击)
                        概述
                            使得目标电脑的网络或系统"资源耗尽",使服务暂时中断/停止,导致其正常用户无法访问
                            就是大量冲击
                        分类
                            带宽消耗型
                                UDP洪水攻击,ICMP洪水攻击
                            资源消耗型
                                SYN洪水攻击,LAND攻击
                                SYN洪水攻击
                                    概述
                                        攻击者发送一系列的SYN请求到达目标,然后让目标因收不到ACK(第3次握手)而进行等待,消耗资源
                                        只发送第一次握手,不发送第三次握手
                                    攻击方式
                                        跳过发送最后的ACK信息
                                        "修改源IP地址",让目标送SYN-ACK到伪造的IP地址,因此目标永不可能收到ACK(第3次握手)
                                            源IP瞎写的,SYN-ACK都不知道发到哪去了
                    DDoS(Distributed Denial-of-Service attack,分布式拒绝服务攻击)
                        概述
                            黑客使用网络上两个及以上被攻陷的电脑作为"僵尸"向特定的目标发送DoS攻击
                            2018年3月,GitHub遭到迄今为止规模最大的DDoS攻击
                        
                    防御
                        入侵检测,流量过滤,多重验证
                            堵塞网络贷款的流量将会被过滤掉,而正常的流量可以正常通过

                        防火墙
                            防火墙可以设置规则,例如允许或拒绝特定通信协议,端口/IP 
                            当攻击从少数不正常的IP发出时,可以简单的使用拒绝规则组织一切从攻击源IP发出的通信
                            复杂攻击难以用简单规则来阻止
                                例如80端口遭受攻击时不可能拒绝端口所有的通信,因为同时也可能会阻止合法流量
                            防火墙可能处于网路架构中过后的位置,路由器可能在恶意流量到达防火墙前被攻击影响
                        交换机 
                            大多数交换机哟一定的速度限制和访问控制能力
                        路由器 
                            也有一定的速度限制和访问控制的能力
                        黑洞引导
                        流量清洗
                            当流量被送到DDoS防护清洗中心时,通过采用DDoS软件处理,将正常流量和恶意流量区分开
                            正常流量则回注客户网站
                DNS劫持(域名劫持)---应用层
                    概述
                        攻击者"篡改"了某个"域名的解析结果",使得指向该域名的IP"变成了另一个IP"
                        导致对响应网址的访问被劫持到另一个不可到达的/假冒的网址
                        从而实现非法窃取用户信息或破坏正常网络服务的目的
                    防护
                        使用比较靠谱的DNS服务器,eg:114.114.114.144
                        谷歌
                            8.8.8.8 8.8.4.4
                        微软
                            4.2.2.1 4.2.2.2
                        百度
                            180.76.76.76
                        阿里
                            223.5.5.5 223.6.6.6
                HTTP劫持
                    对HTTP数据包进行拦截处理,比如插入JS代码

                    比如有的时候,访问网站的时候,右下角出现的毫无关联的弹窗(排除网站自己的弹窗外)
                
            对称加密+非对称加密+数字签名+证书
                HTTP协议的安全问题
                    HTTP协议"默认采用明文传输"的,因此会有很大的安全隐患
                    常见的方式: 对通信的数据"加密"之后再发送给服务器
                        常见的加密方式
                            不可逆
                                单向散列函数
                                    MD5,SHA...
                            可逆
                                对称加密
                                    DES,3DES,AES...
                                非对称加密
                                    RSA...
                            其他
                                混合密码系统
                                数字签名
                                证书
                加密方式
                    不可逆(不可以反向解密)
                        单向散列函数(One-way hash function)
                            概述
                                也称作:消息摘要函数/哈希函数
                                算出来的散列值,也被叫做"消息摘要"/指纹/哈希值
                            特点
                                可以根据"任意长"度的消息内容计算出"固定长度"的散列值
                                    散列值的长度和消息的长度无关,无论消息是1bit,10m,100G,单向散列函数都"会计算出固定长度的散列值"
                                计算速度快,能够计算出散列值
                                消息不同,散列值也就不同
                                    哪怕消息只有1bit不同,算出来的散列值也完全不同
                                具备"单向性"(不可逆)
                                    拿着消息可以算出对应的散列值,但是拿着散列值,推不出来原数据是什么
                            常见单向散列函数
                                MD4,MD5
                                    产生"128位"的散列值,MD(Message Digest),目前已经不安全
                                        可以"暴力反推",穷举出来,然后呢人家破解过的都已经记录过(复杂的密码可能没记录过),所以说...不怎么安全

                                        也不是不能用,只要密码复杂点,还是可以用
                                SHA-1
                                    产生"160bit"的散列值,目前已经不安全
                                SHA-2
                                    SHA-256,SHA-384,SHA-512,散列值长度分别是256bit,384bit,512bit
                                SHA-3
                                    全新的标准
                            应用场景
                                检验数据是否被篡改
                                    比如昨天的文件和今天的文件
                                    将昨天的文件生成一个散列值,再将今天的文件生成一个散列值,两个进行比对

                                    有的官网下载安装包的时候,就有一个散列值在旁边,可以用来做校验下载的包是否为正版,有没有被篡改过
                                密码加密
                                    ...
                                一般网站是不能够提供现在的密码的,因为如果使用这种方式,是不可逆的,所以一般忘记密码都是走重置
                    可逆(可以反向解密)
                        概念
                            密钥
                                密钥就是一串数字/字符串,通过密钥对明文进行加密/解密\
                            对称加密(对称密码)
                                "加密"和"解密"用的是"同一把密钥"
                            非对称加密 (公钥密码)
                                "加密"和"解密"用的是"不同密钥"
                        密钥+算法
                            不管是哪种加密算法,都需要同时具备 密钥+算法 完成
                        对称加密(Symmetric Cryptography)
                            概述
                                对称加密中,"加密"和"解密"用的是"同一把密钥"
                            常见的对称加密算法
                                DES+3DES+AES
                            DES(Data Encryption Standard)
                                概述
                                    DES是将"64bit明文"加密成"64bit密文"的对称加密算法,"密钥长度是56bit"
                                    规格上来说,密钥长度是64位,但是每隔7位就会设置一个用于错误检查的bit,因此密钥长度实质上是56bit
                                    由于DES每次只能加密64bit的数据,遇到比较大的数据,需要对 DES 加密进行迭代(反复)

                                    目前可以在短时间内被破解,所以"不建议使用"
                                条件
                                    64bit的数据,密钥长度是56bit
                            3DES(Triple Data Encryption Standard)
                                概述
                                    将DES重复3次所得到的一种密码算法,也叫做3重DES

                                    并不是进行三次DES加密(加密->加密->加密)
                                    而是加密->解密->加密,用了三把密钥
                                        明文--密钥1加密-->值--密钥2解密-->值--密钥3加密-->密文
                                        密文--密钥3解密-->值--密钥2加密-->值--密钥1解密-->明文

                                        如果三把密钥都不同,称为DES-EDE3
                                        如果密钥1,密钥3相同,密钥2不同,称为DES-EDE2

                                            三把密钥都相同,加密个锤子

                                    目前被一些银行等机构使用,但是"处理速度不高",安全性主键暴露出问题
                            AES(Advanced Encryption Standard)
                                概述
                                    目前AES已经逐步取代DES,3DES成为新标准的一种"对称加密算法",又称为Rijndael加密法,成为了"首选的"对称加密算法
                                    AES的密钥长度有128,192,256bit三种

                                    我们直接使用AES就行
                            所以数据在网络中传输的时候
                                发送之前先协商好用哪种加密方式(eg:AES),然后用什么密钥,好了之后,在发送比较关键的数据之前可以先进行加密,然后发送,服务端再进行解密

                                所以双方就得有一把共同的密钥,但是如果双方从来不知道对方,密钥不可能说前端私下给后端,但是终究是要告诉服务端我用的密钥是啥,这咋整,考虑到"密钥配送问题"
                            
                            密钥配送问题
                                概述
                                    在使用 "对称加密" 的时候,一定会遇到密钥配送问题
                                        密钥在网络传输中也可能是极不安全的,如果密钥被人家搞到手了,那加密加了个寂寞,又不可能说诶又给密钥整个密钥,然后明文传输过去,这不等于0?
                                解决
                                    事先共享密钥
                                        在真正开始传输数据前,客户端和服务端都保存共同的密钥,这样密钥就不会在网络中传输,安全 
                                    密钥分配中心
                                    Diffie-Hellman密钥交换
                                    "非对称加密"
                                        比如A要发送给B
                                        1. B先生成一对 密钥对(公钥+私钥)
                                        2. B将公钥发给A
                                        3. A拿着公钥对密钥进行加密--->密文
                                        4. A将"密文"发给B
                                        5. B用"私钥"解密密文

                                        非对称加密速度要比对称加密慢

                        非对称加密(Asymmetric Cryptography)---公钥密码
                            概述
                                非对称加密中,密钥分为"加密密钥","解密密钥"2种,他们并"不是同一个密钥"
                                "公钥"用于加密,"私钥"用于解密

                                加密密钥/公钥
                                    一般是公开的,因此该密钥称为"公钥"(public key)
                                解密密钥/私钥
                                    是由消息接受者自己保管的,不能公开,因此称为"私钥"(private key)
                            特点
                                公钥和私钥是一一对应的,不能单独生成,一生就是生一对
                                由公钥生成的密文,"必须使用该公钥对应的私钥才能解密"

                                由"私钥"加密的密文,必须使用该私钥对应的公钥才能解密--->就是说反过来也是可以的
                                    但是这种可能会导致用私钥加密的数据,人家谁都可以用公钥去解密,因为都知道公钥,这样看来没啥意义,但是在数字签名中会用到
                            大致过程
                                比如服务器生成一对密钥(公钥+私钥),然后呢,把公钥放出去,随便给,给到坏人也没事
                                客户端拿到公钥之后,以后请求发送数据就用公钥进行加密,然后给到服务器,通过私钥进行解密
                                    加密后的数据被人拿到了也没关系,他不知道私钥,解不了,这样就保证了安全

                                所以一般要给对方发数据,拿着对方的公钥去加密,然后呢数据传过去,对方用自己的私钥解密
                            算法(RSA)
                                RSA算法
                                
                        混合密码系统(非对称加密+对称加密结合)---用私钥解密
                            概述
                                理论上来讲,非对称加密已经够了,已经可以实现网络中数据通信的安全了, 但是呢,非对称加密"很复杂",所以"很安全",但是也导致"效率很低",加密解密"速度很慢"
                                加密对称: 简单--->不安全(密钥会被窃听)--->加密解密很快

                                所以一般要把"对称加密"和"非对称加密"结合起来
                            优势
                                解决了"非对称加密"速度慢的问题
                                通过"非对称加密"解决了"对称加密"的密钥配送问题

                            网络上的密码通信所用的SSL/TLS都运用了混合密码系统
                                HTTPS的S就是用的SSL/TLS
                            概念
                                会话密钥
                                    为本次通信"随机生成的临时密钥"
                                    作为"对称加密"的密钥,用于加密"消息",只能选择"对称加密"啊,提高速度
                                        要是选"非对称加密",估计慢的要死,有的时候消息是很大的

                                        对称加密肯定要有密钥啊,这个密钥随机生成,就是会话密钥,专门为A和B之间的会话准备的
                            加密步骤(加密消息+密钥)
                                本质是要对"消息进行对称加密",然后将"密钥"通过非对称加密传过去
                                拿到消息之后
                                1. 先生成随机的"会话密钥"
                                2. 拿着"会话密钥"对消息进行"对称加密"
                                3. 让接收者生成一对密钥对(公钥+私钥),传给发送者
                                4. 拿着传过来的"公钥"将"会话密钥"进行"非对称加密"
                                5. 然后("对称加密"的消息+"非对称加密"的会话密钥)组合,一并发送给接收方
                                6. 接收方用"私钥"先解密出"会话密钥",然后再用"会话密钥"通过对称解密出消息

                                接收方接收的内容就是: 用公钥非对称加密的会话密钥+会话密钥加密的消息内容

                                即便每次会话密钥变了,也还是可以解析出消息数据,因为消息数据是靠"公钥"和"会话密钥"解密出来的,这两个都是已知的

                                发送方要对消息进行加密,同时呢也将密文告诉接收方,告诉的这个过程是加密的

                            为什么要进行结合呢?
                                "对称加密"加密消息内容会比较快
                                "非对称加密"加密"会话密钥",保证密钥的安全
                数字签名(用公钥解密)
                    场景问题
                        一个消息发送给服务端,那这个内容可能是被篡改过的,或者不是真正的客户端发送的,那么服务端就需要否认这个消息
                            就算加密发送消息,那也可能是伪造的,因为都可以拿到公钥,然后自己生成所谓的"会话密钥",再放上点数据,那么也是可以将消息发送到服务器的
                            现在主要目的就是要去"识别这个消息是不是被伪造出来的","跟加密不加密没什么关系"

                            消息加密只是在数据传输的阶段起到安全性作用,对于是谁发的,是不是伪造的,他也没办法

                        那如何确定这段消息的真实性呢? 如何识别篡改,伪装,对不正确的消息否认呢?

                        使用数字签名/数字证书可以解决这个问题
                    作用
                        仅仅是为了识别内容有没有被篡改+确保消息是否是正确的人发送的

                        确认消息的完整性
                        识别消息是否被篡改
                        防止消息发送人否认
                    概述
                        有点像token哦,给个东西要验证是不是伪造的嘛
                    行为
                        生成签名
                            消息的"发送者"完成,通过"签名密钥"生成 
                        验证签名
                            由消息的"接收者"完成,通过"验证密钥"验证

                        发送的时候实际上是发了两个部分: 消息本体+"签名密钥"生成的数字签名
                        接收的时候就要通过"验证密钥"判断到底是不是正确发送方发的
                    如何保证这个签名是消息发送者自己签的?
                        用消息发送者的"私钥"进行签名
                    过程(消息生产者产生密钥对)
                        1. 直接对整个消息进行"非对称加密"
                            过程(A--->B   假如发送明文消息)
                                1. A生成密钥对,将公钥发送给B
                                2. A用自己的"私钥"对"消息"进行"非对称加密"
                                3. 然后将(密文+消息明文)发送给B,B使用A的"公钥"对消息进行解密
                                4. 比对之前接收到的消息和明文消息是否一致
                                    如果一致,签名验证成功
                                    不一致,验证失败

                            如果能用A的"公钥"解密出来,那说明消息肯定是A发过来的嘛,要不然根本解不出来,而且A的"私钥"只有A才知道,其他人不知道
                                当真A的"私钥"被别人获取了,那也没办法,私钥都搞丢
                            这个当前只是保证确定是谁发的,数据是不是伪造的,暂时不考虑数据传输中的安全啊,如果既要保证传输中的安全防伪造,那么就需要同时采用"混合加密"+"数字签名"两种方式
                        2. 过程改进
                            问题
                                那万一我"消息体太大"了咋整,而且本来"非对称加密就慢的很"
                            改进
                                对消息进行单向散列函数计算,算出它的散列值/指纹/消息摘要,那这个计算出来,消息再大,结果也是128bit的值,拿着这个值去非对称加密,肯定要好得多
                                然后呢,对于消息接收方,收到消息之后也去算一个"散列值",最后拿着解密出来的"散列值"和计算出来的"散列值",两个进行对比,看看是否一致
                            过程(A--->B   假如发送明文消息)
                                1. A生成密钥对,将公钥发送给B
                                2. 发送者先通过"单向散列函数"计算出"消息"的散列值
                                3. 然后A通过"私钥"对这个"散列值"进行"非对称加密"得到一个密文
                                4. 将(密文+消息)发送给B,B使用A的"公钥"对消息进行解密,得到一个"散列值",再拿着消息进行"散列运算"得到一个"散列值2",两个对比
                                    如果一致,签名验证成功
                                    不一致,验证失败
                    疑惑
                        如果有人篡改了消息内容/签名内容,会是什么结果
                            接收方验证会失败,证明内容被篡改了
                        数字签名不能保证机密性?
                            "是的",数字签名的作用不是为了保证"机密性"(混合加密才保证机密性),"仅仅是为了识别内容有没有被篡改"
                加密方式+数字签名总结
                    "非对称加密"中,任何人都可以使用公钥进行加密
                    "数字签名"中,任何人都可以使用公钥验证签名/解密 

                                        公钥                        私钥
                    非对称加密      发送者加密时使用            接收者解密时使用
                    数字签名        验证着验证签名时使用        签名者生成签名时使用
                    谁持有私钥      只要有需要,任何人都可以持有     个人持有
                证书(Certificate)
                    解决了公钥在传输过程中被人劫持替换的问题,公钥传输安全⭐️
                    存在的问题
                        公钥合法性
                            如果遭遇了中间人的攻击,那么公钥可能是伪造的

                            就是说啥呢
                                A---B发送数据,,如果有个中间人C进行攻击,当B作为接收方将自己的公钥发送给A时,那么如果C中间做个阻断,拿到B的公钥,然后保留下来,给A发的却是自己的公钥,那么A拿到的就是C的公钥
                                然后A用C的公钥去进行"非对称加密",最后发数据出去,然后C又拦截到了,这个时候它拿着自己的"私钥"去进行解密(是可以解开的,A毕竟拿的是C的"公钥"进行加密的),然后呢把数据解出来了(先得到密文,再通过密文得到数据),然后呢,拿着从A解析出来的数据,用保存在本地的B的"公钥"去加密数据,伪造一个请求,发送给B,那么B收到之后,也会同样进行使用"私钥"解析,解析成功之后把数据返回出去,那C又可以拦截到B原本想发给A的数据

                                这样其实,公钥被拦截/窃听到了,那也是不安全,数据还是被别人窃取了

                                攻击者在中间捣乱,搁那狸猫换太子,把公钥给人换了

                                "A不确定公钥到底是不是来自B",还是被伪造的

                                

                            以前默认公钥就送过去了,公钥作为加密"密钥"的"密钥",要保证对称加密的安全,所以要对"密钥"保证安全传输,那现在要保证"公钥"的安全传输并且不被篡改!

                            只要牵扯到网络中发送公钥,就避免不了被中间人攻击,公钥被人伪造/替换他们自己的公钥
                                所以"非对称加密"和"数字签名"都避免不了这个问题
                                    签名也涉及到把公钥发给别人用来解密,所以还是可能被替换/伪造

                        所以就需要验证公钥的合法性,怎么验证呢? 用到"证书"
                    概述
                        密码学中的证书,全称叫"公钥证书"(Public-key Certificate,PKC),是由权威机构认证的
                        里面包含
                            姓名,邮箱等个人信息,以及此人的"公钥"
                        由认证机构(Certificate Authority,CA)"施加"数字签名
                            用"CA的私钥"施加数字签名,那CA的私钥肯定伪造不了的
                        CA是能够认定"公钥确实属于此人",并且能够生成数字签名的个人或组织
                            有国际性组织,政府设立的组织
                            有通过提供认证服务来盈利的企业
                            个人也可以成立认证机构

                        浏览器下载的时候是从服务器去下载到证书的⭐️
                    公钥证书
                        个人信息
                        个人公钥
                        
                        就是将要加密的公钥作为数据,加密得到一个数字证书,然后呢,顺带也要把原始证书带过去,方便后面校验两个是否一致
                    流程⭐️⭐️⭐️
                        A--->B,保证公钥的安全传输
                        1. B生成密钥对,然后呢把公钥给到认证机构(这个过程不用管啊,是保证安全的,CA会线上线下审查)
                        2. CA机构根据B的公钥生成证书
                            拿到B的公钥,CA通过自己的"私钥"对B的公钥加密生成"数字签名"
                            个人信息+B的公钥会包含在证书中
                            数字证书包含对应的数字签名
                            生成好了证书之后会发送给服务器B
                        3. 服务器会将证书发送给A,A拿着CA的公钥对 服务器证书中的数字签名 "解密",得到一个公钥,然后这个公钥和证书里面的公钥进行对比
                            如果一致,说明"公钥"没有被篡改过
                            如果不一致,说明"公钥"被篡改过
                        4. 接着,A就可以拿着B的"公钥"对"对称加密"的"密钥"加密,保证"密钥"安全...

                    验证流程
                        1. 客户端 C 向服务器 S 发出https请求时，S 返回证书文件到客户端；
                        2. 客户端首先在本地电脑寻找是否有这个服务器证书上的ca机构的根证书。如果有继续下一步，如果没有弹出警告，认为证书是非法的。
                        3. 客户端会内置信任CA的证书信息，包括CA的公钥。
                        4. 客户端C使用CA机构根证书的公钥对服务器证书的签名和签名算法（散列函数）进行解密，得到摘要（签名解密后就是摘要）和散列函数。
                        5. 客户端 C 读取证书中的相关的明文信息，采用得到的散列函数计算得到信息摘要，对比得到的摘要和自己计算出的摘要是否一致，如果一致，则可以确认证书的合法性，即服务器的公钥合法；
                        6. 客户端然后验证证书相关的域名信息、有效时间等信息；

                    
                    公钥的注册和下载
                        注册
                            B从认证机构CA进行注册,注册成功之后,CA会将证书保存到"仓库"
                        下载
                            A从"仓库"下载对应的证书

                            上网的时候,浏览器会去下载很多证书...
                        
                        "各大CA的公钥,默认已经内置在浏览器和操作系统中"

            HTTPS(HyperText Transfer Protocal Secure)---超文本传输安全协议
                概述
                    常称为HTTP over TLS,HTTP over SSL, HTTP Secure
                    网景公司在1994年首次提出

                    默认端口443,HTTP默认端口80

                    如果访问http://www.baidu.com 
                        服务器会返回一个重定向的状态码307,然后"重定向"到https://www.baidu.com
                分层
                    HTTP--->SSL/TLS--->TCP--->IP--->MAC
                SSL/TLS
                    概述
                        HTTPS是在HTTP的基础上使用了SSL/TLS来"加密报文",对"窃听者"和"中间人"提供了合理的"防护"
                            HTTP+SSL/TLS=HTTPS

                            通道都是加密了的,就算窃听者拿到了数据,那"所有内容"都是加密了的
                        SSL/TLS也可以用在其他协议上,比如
                            FTP->FTPS
                            SMTP->SMTPS
                    TLS(Transport Layer Security)---"传输层"安全性协议
                        前身是SSL(Secure Sockets Layer)---安全套阶层
                    历史版本信息
                        SSL 1.0: 因存在严重的而安全漏洞,从未公开过
                        SSL 2.0: 1995年,于2011年弃用
                        SSL 3.0: 1996年,于2015年弃用
                        TLS 1.0: 1999年
                        TLS 1.1: 2006
                        TLS 1.2: 2008 ---目前用的比较多
                        TLS 1.3: 2018
                    SSL/TLS"工作在应用层与传输层之间"
                        HTTPS无非是对HTTP的报文进行加密,HTTP的报文无非最终是要传递给传输层,所以要在给到传输层之前进行加密

                        传输层不管加密不加密的,只要给到传输层,就拆拆拆,拆成很多段然后发出去
                    OpenSSL
                        OpenSSL是SSL/TLS协议的"开源实现".始于1998年,支持Windows,Mac,Linux等平台
                            Mac和Linux自带OpendSSL
                            用了OpenSSL就可以使用 SSL/TLS 中的一些功能(生成私钥,生成公钥...)

                        可以使用OpenSSL构建一套属于自己的CA,自己给自己颁发证书,称为"自签名证书"
                            但是浏览器只能辨别靠谱的机构证书,哈哈
                HTTPS成本
                    并不是所有公司都用了HTTPS,是要考虑一些成本的

                    证书费用
                    加解密计算
                        相对比HTTP来说,降低了访问速度,当然,也可以慢慢优化
                    有的企业的做法(两者混用)
                        包含敏感数据的请求才使用HTTPS,其他保持HTTP
                        eg 
                            工商银行
                HTTPS通信过程
                    总的分为3大阶段
                        1. TCP的三次握手
                        2. "TLS的连接"(1.2)
                        3. HTTP请求和响应

                        就是在以前的基础上多了一步TLS的连接,从下到上
                            以前是TCP三次握手,建立TCP连接之后,就直接HTTP请求发数据了
                            现在是TCP三次握手之后,再进行TLS的连接,然后才是HTTP请求发数据
                    TLS 1.2 连接 
                        就是协商
                            TLS版本,加密套件(用什么加密算法,摘要算法,非对称加密算法...),其他信息

                            中间省略了一些ACK啊
                        1. Client Hello
                            客户端--->服务器 
                            发送的数据
                                TLS版本
                                支持的加密组件(Cipher Suite)列表
                                    加密组件是指所使用的"加密算法"及"密钥长度"等
                                一个"随机数"
                            会伴随一个从服务端过来的ACK
                        2. Server Hello
                            服务器--->客户端
                            发送的数据
                                TLS版本
                                选择的加密组件(Cipher Suite)
                                    是从接收到的客户端的加密组件列表中挑选出来的
                                一个随机数
                        3. Certificate(公钥证书)
                            服务器--->客户端
                            发送的数据
                                服务器的公钥证书(被CA签名过的)
                        4. Server Key Exchange
                            服务器--->客户端
                            发送的数据  
                                用来实现ECDHE算法中的 其中一个参数(Server Params)

                                ECDHE 是一种"密钥交换算法"
                                    用来决定最终要用什么密钥进行加密
                                为了防止伪造,Server Param仅过了服务器私钥签名
                        5. Server Hello Done
                            告诉客户端,协商部分结束

                            前5部是用来"协商"的,都是用明文传送的

                            Client Hello
                            Server Hello, Certificate,Server Key Exchange, Server Hello Done

                            前五步小总结
                                客户端告诉服务器啊
                                    客户端的TLS版本,支持的加密套件有哪些
                                然后服务器呢,就回复客户端
                                    服务端的TLS版本
                                    最终选择了哪个加密套件
                                    服务器的"公钥证书"
                                    交换算法中的一个参数
                                然后协商结束

                                共享了
                                    Client Random,Server Random,Server Params

                                    "公钥证书",接下来客户端会验证证书的正确性
                                        由于浏览器已经存储了CA的公钥,于是就拿着这些公钥去验证证书是否靠谱

                                        如果没问题,就可以拿到服务器的公钥,然后进行加密传输

                                    也就是说"证书"是"服务器给到客户端的"
                        6. Client Key Exchange
                            客户端--->服务器
                            发送的数据
                                用来实现ECDHE算法的"另一个参数"(Client Params)
                            过程
                                目前为止,客户端和服务器都拥有了"ECDHE算法"需要的两个参数,Server Params+Client Params
                                客户端,服务器都可以使用ECDHE算法

                                根据这两个参数计算出一个新的随机密钥串: Pre-master secret

                                然后结合Client Random,Server Random,Pre-master secret生成用于加密会话的"会话密钥"

                                三个随机值就是用来生成"会话密钥"的,是结合了双方给的信息生成的,为了安全

                            TLS密钥交换---保证两边用的密钥是一样的
                                是通过两个参数进行交换的
                                两边的密钥肯定要是一样的啊,所以客户端提供一个参数,服务端提供一个参数,只有交换之后才能得到相同的密钥嘛

                                以前 
                                    以前是通过对"密钥"进行非对称加密,然后传过去
                                现在 
                                    现在是你给我一个参数,我给你一个参数,然后把密钥"算出来"(两个参数生成一个随机值,然后三个随机值得到一个"会话密钥"),不用再是手动把"密钥"丢给对方
                            主密钥
                                其实三个随机值产生的"会话密钥"也不是最终使用的密钥,而是一个"主密钥"
                                最终利用"主密钥"衍生出其他密钥: 客户端发送用的会话密钥+服务器发送用的会话密钥...

                                那么客户端和服务器两边都会存储这些密钥,而不是像之前还要给传过去
                        7. Change Cipher Spec
                            客户端--->服务器 
                            告诉服务器,之后的通信会采用计算出来的会话密钥进行加密,仅仅是个通知包
                        8. Finished---相当于是个测试
                            客户端--->服务器 
                            告诉服务器TLS连接差不多了

                            包含连接至今"全部报文的整体校验值"(摘要值),利用"会话密钥"加密之后发送给服务器
                                由于服务器那边也已经产生了对应的密钥,所以"直接加密发过去"就得了,也不用把什么密钥发给服务端,人家有了还发什么发

                                相当于验证 客户端的发送密钥

                            这次握手协商是否成功,要以服务器"是否能够正确解密该报文"作为"判定标准"---相当于测试
                                故意发一个加密报文过去,看看服务器是否能够正确解密,如果能,那说明中途数据每出现什么问题,没有被人篡改之类的

                        9+10. Change Cipher Spec + Finished   相当于"验证服务端的发送密钥"
                            服务器--->客户端

                            到此为止,客户端服务器都验证加密解密没问题,握手正式结束
                            后面就开始传输加密的HTTP请求+响应
                            Change Cipher Spec
                                通知客户端,我要给你发加密之后的数据啦
                            Finished
                                服务端也会给客户端发送一份加密之后的数据过来,看看客户端能不能解析成功
                        TLS密钥交换---保证两边用的密钥是一样的
                            是通过两个参数进行交换的
                            两边的密钥肯定要是一样的啊,所以客户端提供一个参数,服务端提供一个参数,只有交换之后才能得到相同的密钥嘛

                            以前 
                                以前是通过对"密钥"进行非对称加密,然后传过去
                            现在 
                                现在是你给我一个参数,我给你一个参数,然后把密钥"算出来"(两个参数生成一个随机值,然后三个随机值得到一个"会话密钥"),不用再是手动把"密钥"丢给对方
                        主密钥
                            其实三个随机值产生的"会话密钥"也不是最终使用的密钥,而是一个"主密钥"
                            最终利用"主密钥"衍生出其他密钥: 客户端发送用的会话密钥+服务器发送用的会话密钥...

                            那么客户端和服务器两边都会存储这些密钥,而不是像之前还要给传过去
                        总的来讲
                            前五步是互相交换信息进行协商

                            第六步数据交换完了,自然是要生成一个随机"会话密钥"出来
                                咋搞个随机会话密钥出来呢?
                                    客户端给服务端一个参数,然后捣鼓捣鼓,搞一个"会话密钥"出来
                                    两个参数--->新的随机密钥串
                                    三个随机值生成一个会话密钥
                            
                            "会话密钥"出来了,自然是要测试一下,看看行不行.客户端就用"会话密钥"加密个数据测试一下,当然测之前要通知一下服务端
                                加密啥数据呢,干脆把之前的报文全部拿过来加密测试

                            服务端解密没问题就OK了
                            
                            服务端再测一下它的发送密钥(9+10)


                            之后就开始传输加密的HTTP请求+响应
                                用的这个"会话密钥"呢,是每一次会话随机生成的,别人算不出来,而且也解不出来

                                而且加密这个"会话密钥"的公钥,是用CA的公钥去解密证书中的"数字签名"得到的公钥,这个东西肯定是服务器给的,到时候解密会话密钥,自然也是需要用服务器的"私钥"才能解密


                            (1,2,3,4,5)--->交换信息
                            6--->客户端给服务端参数,生成主密钥+其他密钥
                            (7,8)--->客户端测一下发送密钥
                            (9,10)--->服务端测一下发送密钥
                    注意
                        服务端存储了证书,客户端在建立TLS连接的时候,服务端就会把证书给到客户端

                        jks(java keystore)
                            JKS文件由公钥和私钥构成,其中的公钥就是我们所说的证书,而私钥就是密钥
                        .cer 和 .crt 
                            Windows中的证书扩展名有好几种，比如.cer和.crt。
                            通常而言,".cer"文件是二进制数据，而".crt"文件包含的是ASCII数据
                        如果服务器调用其他HTTPs请求,怎么搞
                            假如A调用B,那肯定A要具备验证HTTPS的能力,B要有相应的证书
                            那不可能每次自己去写验证HTTPS的代码,比如java用jdk库里的就行
            HTTP的升级改进
                HTTP协议的不足(HTTP/1.1)---HTTP/HTTPS
                    1. 同一时间,一个连接只能对应一个请求
                        对,HTTP/1.1 同一个连接可以复用,但是同一时间,只能有一个请求,如果这个连接内,前一个请求没处理完,后面的请求只能等着

                        针对"同一个域名",大多数浏览器允许"最多同时开6个并发连接"
                    2. 只允许客户端主动发起请求
                        某些时候,加载一个网站的时候,要发送很多请求(css啊,图片啊,js啊...)
                        HTTP/1.1 无法办到,只发送一次请求,服务端就可以返回多个资源,而是每次要用到这些资源的时候,又再去发送请求,属于"请求应答"的模式
                    3. "一个请求只能对应一个响应"
                    4. 同一个会话的请求当中,头信息会被多次"重复传输"(有点浪费)
                        比如cookie...

                        通常会给每个传输增加500~800字节的开销
                        如果使用Cookie,增加的开销有时会达到上千字节
                SPDY(speedy的缩写)---已经停止支持   HTTP/2前身
                    概述
                        是基于TCP的应用层协议,强制要求使用SSL/TLS

                        2009年11月,Google宣布将SPDY作为提高网络速度的内部项目
                    跟HTTP的关系
                        SPDY并不是用来取代HTTP的,只是修改了HTTP的请求与相应的传输方式
                            以前 
                                HTTP--->TCP 
                                HTTP将数据发给TCP,TCP进行分段发送
                            现在 
                                HTTP--->SPDY--->TLS--->TCP--->IP...
                                SPDY会对HTTP报文进行各种处理,使得他传输更快,最终再加密,然后交给TCP
                        如果想将HTTP升级到SPDY,"只需要加一个SPDY层",现有的所有服务端应用均不用做任何修改
                            比如我的项目本来使用http的,然后我要改成SPDY,那么前端和后端代码全都不用动,前后端代码都是面向HTTP的
                        SPDY是HTTP/2的前身
                            2015年9月,Google宣布移除对SPDY的支持,拥抱HTTP/2,废了
                HTTP/2
                    概述
                        2015年5月正式发表
                        截止2019.6 ,全球有36.5%的网站支持了HTTP/2
                    
                        HTTP/2在底层传输上做了很多的改进+优化,但在语意上完全与HTTP/1.1 兼容
                            比如 GET,POST,StatusCode,各种Headers都没有改变
                        因此如果想升级到HTTP/2
                            "开发者不需要修改任何代码"
                            只需要"升级服务器配置","升级浏览器"即可
                        HTTP/2 不强制使用SSL/TLS
                            但是现在基本上只要用了HTTP/2的网站/公司,都是用了SSL/TLS的

                            一般建议加上SSL/TLS,因为现在传输很快了嘛,搞安全一点,速度也很快啊
                    TCP及以下的层
                        是操作系统内核在处理,如果升级TCP,再怎么得升级操作系统内核,内核要改代码,硬件之类的要用新标准,所以很多时候TCP新特性都没有用上,成本有点大
                        
                        不像是应用层,代码都不需要动,升级一下软件/配置就可以了
                    新特点
                        1. HTTP/2采用"二进制格式"传输数据,而非HTTP/1.1 的文本格式
                            HTTP/1.1 传输的就是字符串,然后数据报(请求头啊,请求体...)给TCP,TCP将这些字符串分成段...

                            HTTP/2 传输的就是二进制格式传输数据,拆分成一块一块的帧
                                请求头对应 Headers frame--->请求头帧  
                                请求体/数据对应 DATA frame--->数据帧
                                ...

                                先打散之后再传输

                        2. 二进制格式在协议的解析和优化扩展上"带来更多的优势"和可能

                    分层
                        HTTP--->HPack+Stream--->TLS1.2+--->TCP--->IP--->MAC
                    基本概念
                        数据流(相当于是一根管道)---逻辑上的概念
                            一个请求可能对应多个流
                            已建立的连接内的"双向字节流",可以承载一条或多条"消息"

                            所有的通信都在"一个TCP连接"上完成,此连接可以承载"任意数量"的双向字节流/数据流
                                一个TCP连接上有很多个数据流,一个数据流里面可能包含多次请求响应⭐️

                            实际发送的时候,是每个数据流里面的数据交错发送
                        消息(二进制内容)
                            与逻辑HTTP请求/响应消息对应,"由一系列的帧组成"
                                以前不是发的文本字符串数据吗? 那HTTP/2不是要把他转成二进制嘛,这些数据转成二进制之后的内容就是"消息"
                        帧
                            HTTP/2通信的最小单位,每个帧都包含"帧头"(会"标识"出当前帧"所属的数据流")

                            来自不同数据流的帧可以交错发送,然后再根据每个帧头的"数据流标识符"重新组装

                                数据流只是逻辑上的概念,实际发送过去的时候,交错发送
                                    比如先发2号数据流的,再发1号数据流的消息,然后再发3号,1号... 这种交错发送
                                    然后收到数据之后,再根据每个帧头的"数据流标识符"重新组装

                                    发的时候不用管这些帧的顺序,但是拼接的时候要管
                    HTTP/2 新特性
                        "多路复用"(Multiplexing)
                            概述
                                客户端和服务器可以将HTTP消息分解成互不依赖的帧,然后交错发送,最后再在另一端将他们重新组装起来
                            特点
                                "并行"交错地发送多个请求,请求之间互不影响
                                "并行"交错地发送多个响应,响应之间互不干扰
                                使用"一个连接并行发送多个请求和响应"
                            小结
                                不必再为绕过HTTP/1.1 限制而做很多工作
                                    以前如果有多个请求,同一个时间之内,只能有一个请求,浏览器最多六个并行连接
                                    搞得开发者使用各种手段去提高网速
                                        尽量减少请求数量
                                            比如 雪碧图,合并CSS/JS,内嵌CSS/JS/Base64图片,域名分片...
                                                CSS/JS文件太多,肯定要发很多请求,把它们合并就可以减少请求数量

                                就是很多个请求/响应都在一个连接上发送,一个连接上有很多流
                                    多个请求对应了多个流,交错发送他们的数据,那就是并行嘛
                                        A请求对应了123数据流,B请求对应了245数据流,然后交错发送这些数据流中的数据帧,发过去就是34215... 那相当于A请求和B请求就是并行的嘛,都在同时发送
                                
                                    因为底层还是TCP嘛,TCP拿数据的时候还是按照顺序拿,所以数据顺序不用担心
                                对比
                                    以前
                                        以前是发一个请求得到一个响应,然后再发一个请求,再得到一个响应
                                    现在(并发)
                                        发一个请求,得到一个响应,然后发现还有很多很多css/js,那就可以下一次一次性发送很多个请求css/js的请求,然后服务端将这些css/js全部返回 
                        优先级
                            HTTP/2标准允许每个"数据流"都有一个"关联的权重"和依赖关系
                                可以向每个数据流分配一个介于1~256之间的整数,每个数据流与其他数据流之间可以存在显式"依赖关系"
                            客户端可以构建和传递"优先级树",表明它倾向于如何接受响应
                            服务器可以使用此信息通过控制CPU,内存和其他资源的分配设定数据流处理的优先级
                                在资源数据可用之后,确保将高优先级响应以最有方式传递给客户端
                        头部压缩
                            会跟踪以前发过的请求,看他们请求头和当次的请求头进行对比,"只发不一样的请求头"

                            HTTP/2使用HPACK压缩请求头+响应头
                                可以极大减少头部开销,进而提高性能
                            早期版本的HTTP/2和SPDY使用zlib压缩
                                可以将所传输头数据的大小减小85%~88%
                                但在2012夏天,被攻击导致会话劫持
                                后被更安全的HPACK取代
                        服务器推送---服务器返回多个响应
                            服务器可以"对一个客户端请求发送多个响应"
                                除了最初请求的响应外,服务器还可以向客户端推送额外资源,而"无需客户端额外明确地请求"

                                只要是HTTP,都是请求应答,就是你只有先发请求,我才能给响应,而不是我直接给响应

                                节省了请求
                    HTTP/2 的问题 (本质还是TCP的问题)
                        "队头阻塞"(head of line blocking)
                            本质是TCP底层的问题
                                HTTP/2 底层还是基于TCP嘛,假如说多个请求,那TCP接收数据的时候要保证有序,而如果前面有个数据丢了,那后面的那些请求都要等着,要等丢掉的那个数据帧重传之后才能继续,搁那等着阻塞

                                TCP发现数据丢失了,传输失败,也会抛给应用层,所以应用层也知道传输失败了
                            QUIC 协议解决了这个问题
                                因为底层用的UDP... UDP嘛,往对面扔就完事了,管你接收到没
                        "握手延迟"
                            底层TCP 
                            握手很慢,如果是TLS,那握手更慢
                            RTT(Round Trip Time): 往返时延,通信一来一回的时间

                            QUIC 是 0RTT
                                底层UDP,都不用等响应和建立连接
                HTTP/3---试验中...
                    概述
                        Google觉得HTTP/2仍然不够快,于是有了HTTP/3
                        
                        HTTP/3由谷歌开发,弃用TCP协议,使用基于UDP协议的QUIC协议进行实现,2013年实现
                            HTTP/3底层就是UDP
                    QUIC(Quick UDP Internet Connections)---快速UDP网络连接

                    分层
                        HTTP--->QPack+Stream--->QUIC+TLS1.3 +--->"UDP"--->IP--->MAC
                    HTTP/3基于UDP传输的,如何保证可靠传输呢?
                        "由QUIC来保证"
                            UDP肯定保证不了嘛,那只能靠QUIC保证了

                            UDP如果丢包了,那么传给QUIC的包肯定也就少了,那么QUIC层之前是有沟通的,会进行检测校验
                    Google为啥不自己开发协议取代TCP/UDP呢?---考虑到兼容问题
                        目前世界上的网络设备只认识TCP和UDP
                        如果要修改传输层,操作系统内核也要改变
                        IETF标准化的"许多TCP新特性"都因"缺乏广泛支持"而没有得到广泛的部署+使用
                            连TCP的新特性都没法广泛部署和使用,更别说直接来个新标准了,操作系统,内核,网络设备全都要变
                    新特性
                        连接迁移
                            概述
                                TCP基于4要素(源IP,目的IP,源端口,目标端口)
                                切换网络的时候至少有一个要素发生变化,导致连接发生变化
                                    比如正在上网,手机网络突然变成WIFI,然后那ip肯定变了啊,那之前的连接就无效了,GG,找不到服务端返回数据的时候找不到目标IP了,所以超时,超时之后会重连,所以这就是为什么有时候切网络的时候,要小等一会,因为这是超时,重新建立连接了

                                    即便处理的很好,还是要等待几百毫秒
                            QUIC 的连接不受这4要素的影响,当这4个要素发生变化时,原连接依然发生变化
                                不是以4要素作为标识的,而是使用一组ConnectionID来标识一个连接
                                即便端口/IP发生变化,只要ConnectionID没有变化,那么连接依然可以维持

                                eg:
                                    正在下载文件,将蜂窝--->WIFI,那么下载依旧继续

                                但是UDP和IP层都还是需要4要素的,只不过QUIC不再以4要素作为判断连接的依据而已,在传输层和网络层的上一层维护一个ConnectionID的东西
                    HTTP/3 问题 
                        操作系统内核+CPU负载---优化问题
                            Google+Facebook发现,与基于TLS的HTTP/2相比,大规模部署的QUIC需要近2倍的CPU使用量
                            Linux内核的UDP部分没有得到像TCP那样的优化,因为传统上没有使用UDP进行如此高速的信息传输,都是用的TCP多一点
                            TCP和TLS有硬件加速,对于UDP很罕见,对于QUIC基本不存在加速
            其他协议
                ARP(Address Resolution Protocal)---地址解析协议
                    通过IP地址解析MAC地址
                RARP(Reverse Address Resolution Protocal)---逆地址解析协议---淘汰
                    使用ARP相同的报头结构
                    作用与ARP相反,用于将"MAC地址转换为IP地址"
                    后来被BOOTP,DHCP取代
                ICMP(Internet Control Message Protocal)---互联网控制消息协议
                    IPv4中的ICMP被称作ICMPv4,IPv6中的ICMP被称作IPv6
                    ping就是用的ICMP协议
                    通常用来返回错误信息
                        比如TTL过期,目的不可达
                    ICMP的错误信息总是包括了源数据并返回给发送者
            WebSocket协议  
                Socket
                    一套网络API,利用它可以建立网络连接
                
                HTTP 的"推送"问题
                    Http请求特点
                        通信只能由客户端发起,典型的"请求应答"模式
                            所以,早期很多网站为了实现"推送"技术,所用的技术就是轮询,每隔一段时间向服务器发出HTTP请求,然后服务器返回最新的数据给客户端
                                每一次发请求过去都有数据更新吗? 不一定,那这就挺耗费资源了嘛,如果多个客户端去轮询,服务器很可能G
                            推送
                                客户端无需请求,而是由服务端主动推送数据给客户端
                        
                    为了能够更好地"节约服务器资源和带宽",并且能够更实时地进行通讯,"HTML5"规范中出现了"WebSocket协议"
                概述
                    WebSocket 是基于TCP的支持"全双工通信"的"应用层协议"

                    客户端,服务器任何一方都可以主动发消息给对方
                应用场景
                    社交,订阅,股票,实况更新...
                HTTP 对比 WebSocket
                    WebSocket和HTTP是"平级"关系,都是应用层协议
                        其实TCP本身就是支持"全双工"通信的,即客户端,服务器任何一方都可以主动发消息给对方
                            只是HTTP采用的是"消息应答"的模式,限制了TCP的能力
                    WebSocket使用80("ws://")+443("wss://")端口,可以绕过大多数防火墙的限制(一般都是开了80+443)
                        使用80和443是为了兼容HTTP和HTTPS协议
                        ws://example.com/xxxapi
                        wss://secure.example.com/xxxapi
                    与HTTP不同的是,WebSocket需要先建立"应用层的连接"
                        HTTP是在传输数据前,要先建立TCP的连接,而WebSocket是先建立TCP连接,然后建立应用层连接,最后才传输数据

                        这样就使得WebSocket成为一种"有状态"的协议,"之后通信时可以省略部分状态信息"
                            它知道跟谁连着
                        而HTTP是"无状态"的,可能需要在每个请求都额外地携带状态信息(如身份认证cookie...)
                WebSocket建立连接 
                    WebSocket需要借助"HTTP协议"来建立连接(应用层的通道相当于,然后以后服务端就通过这个通道主动发数据过来)
                        由客户端/浏览器主动发出握手请求
                            一个HTTP的GET请求
                                请求头 
                                    Upgrade: websocket 
                                    Connection: Upgrade
                                    Sec-WebSocket-key: xxx
                                    Sec-WebSocket-Protocal: chat,superchat
                                    Sec-WebSocket-Version: 13
                                "Connection必须设置为Upgrade",表示客户端希望连接"升级"
                                "Upgrade必须设置为websocket",表示希望升级到WebSocket协议
                                Sec-WebSocket-Version
                                    表示支持的WebSocket版本
                                Sec-WebSocket-key
                                    客户端随机生成的随机字符串
                        服务器响应
                            响应头
                                Upgrade: websocket 
                                Connection: Upgrade
                                Sec-WebSocket-Accept: xxx 
                                Sec-WebSocket-Protocal: chat
                            服务端收到Sec-WebSocket-Key后,会进行如下操作
                                1. 将客户端传过来的Sec-WebSocket-key加上一个"固定的"GUID值(定死的啊)
                                2. 将1的结果进行SHA-1摘要计算
                                3. 将2的结果进行Base64编码
                                4. 将3的结果作为Sec-WebSocket-Accept响应头的值,返回给客户端

                                如此操作,可以尽量避免普通HTTP请求被误认为WebSocket协议
                        涉及到前端代码
                            let ws=new WebSocket("wss://example.com");
            WebSevice
                概述
                    Web服务,是一种跨编程语言和跨操作系统平台的"远程调用技术标准"
                        就是遵循一定标准的"开放"远程调用嘛
                    
                    有点古老的技术
                使用场景
                    天气预报,手机归属地,航班信息,物流信息查询...
                逐渐淘汰
                    现在很多公司不用了,是一套比较旧的标准(数据通过XML文档传输,现在谁还用这种方式啊),现在服务器都是跨平台跨语言的了,很多都采用json嘛,或者其他格式
                    WebService完全可以用普通的Web API取代(比如 HTTP+JSON)

                    如果想开放API给开发者调用,这就属于是开放平台,很多都直接采用Web API (告诉你URL+需要的参数,然后返回数据给你)
                        要注册成对应平台的开发者啊
                核心概念
                    SOAP(Simple Object Access Protocal)---简单对象访问协议
                        很多时候,SOAP=HTTP+XML

                        WebService使用SOAP协议来封装传递数据
                            客户端和服务端之间隔了两个SOAP,两个SOAP进行通信,然后客户端和服务端各自关联对应的SOAP
                                客户端<--->SOAP<--XML文档-->SOAP<--->服务端

                            客户端还是发送HTTP请求,服务端响应还是HTTP请求,只不过请求/响应的数据都是"XML文档"
                                比如发请求的时候,请求体就是XML文档
                                数据响应的时候,响应体就是XML文档
                        "SOAP协议规定了传输的XML文档应该怎么写"

                        举例
                            如果发送个HTTP的SOAP 请求 
                                POST /xxx/xxx HTTP/1.1
                                Host: xxxxx:xxx
                                Content-Type: application/soap-xml;charset=utf-8
                                ...

                                <?xml Version="xxx" ...></xml>
                    WSDL(Web Service Description Language)---Web服务描述语言
                        也是一个XML文档,用来描述 WebService "接口的细节"(比如参数,返回值等)---相当于接口文档

                        一般是在WebService的URL后面跟上?wsdl获取WSDL信息
                            http://example.com/xxxpai?wsdl

                    WebService调用要遵循SOAP的格式,也就是HTTP+XML 
            HTTPDNS
                概述
                    HTTPDNS是基于HTTP协议向DNS服务器发送域名解析请求
                        之前
                            发送DNS协议请求给DNS服务器,DNS底层基于TCP/UDP
                        现在
                            发送HTTP请求给DNS服务器,而DNS服务器实际上是一台"HTTP服务器",只不过功能跟DNS服务器是一样的
                作用
                    替代了 基于DNS协议向运营商Local DNS发起解析请求的"传统方式"
                        传统来讲,DNS服务器一般是ISP提供的
                    避免Local DNS造成的域名劫持和跨网访问问题

                    常用在"移动互联网"中(Android,IOS,Win桌面开发)
                        浏览器一般"默认"走的操作系统配置的DNS(即传统DNS),基本不会走HTTPDNS
                        只有移动端可以进行手动配置走HTTPDNS还是传统方式
                优势
                    ...
                使用 
                    市面上现在已经有了现成的方案,移动端继承相关的SDK即可使用HTTPDNS服务
            FTP(File Transport Protocal)
                概述
                    基于TCP的应用层协议,对文件上传和下载做了优化
                    ftp://user:password@host:port/xxx/xxx
                连接模式
                    FTP两种连接模式
                        主动(Active)
                        被动(Passive)
                    不管哪种模式,都需要客户端和服务器"建立两个连接"
                        HTTP只需要建立一个连接

                        1. 控制连接: 用户传输状态信息(命令,cmd...)
                        2. 数据连接: 用于传输文件和目录信息(data/文件...)

                        相当于两个通道嘛
                    主动模式
                        概述
                            第一次连接建立好之后,服务器主动再去连客户端
                        步骤
                            1. 客户端打开一个"随机"的"命令端口"(假设为C)
                                端口需大于1024
                                同时连接至服务器的21命令端口(FTP端口就是21)
                            2. 客户端开始监听(C+1)端口
                                同时向服务器发送一个Port命令给服务器的"命令端口21"
                                    通过C端口发送Port命令告诉服务器,我用来接收数据的端口是(C+1),并且已经准备好了,可以给我发数据了
                            3. 服务器打开20端口,并创建和客户端数据端口(C+1)的连接 
                            
                            就是两边各自开两个端口,客户端随机开连续的两,然后第一次先跟服务器的21建立连接(命令端口),然后告诉服务器我用来接收数据的是哪个端口,然后服务器拿到之后,就建立和这个接收数据的端口的连接,用来传输数据

                            客户端告诉服务器,客户端用哪个端口用作传输数据,然后服务器拿到这个端口之后,主动用20端口去跟服务器连接
                    被动模式
                        概述
                            在告诉服务器用于传输数据的端口是哪个之后,服务器被动地等着客户端去连接
                        步骤
                            1. 客户端打开一个"随机"的"命令端口"(假设为C)
                            2. 客户端通过C端口发送PASC命令给服务器的命令端口21
                                告诉它这是被动模式
                            3. 服务器返回一个随机端口IP,并告知客户端与该端口S
                            4. 客户端数据端口C+1发起与服务器数据端口S的连接

                            关键就是看发数据的那个连接是服务器主动还是被动发起

                            客户端告诉服务器这是个被动请求,然后服务器决定用哪个端口传数据,告诉客户端,然后服务器被动等着客户端去连接这个端口
            邮件协议
                发邮件使用的协议
                    SMTP(Simple Mail Transfer Protocal)---简单邮件传输协议
                        基于TCP
                            肯定要保证数据完整可靠传输啊
                        服务器默认端口25,SSL/TLS使用465端口
                收邮件使用的协议
                    POP(Post Office Protocal)---邮局协议
                        基于TCP
                            最新版是POP3
                        服务器默认使用110端口,SSL/TLS使用995端口
                    IMAP(Internet Message Access Protocal)
                        基于TCP
                            最新版IMAP4
                        服务器默认使用143端口.SSL/TLS使用993端口
                    POP和IMAP区别
                        POP
                            当客户端连接服务器的时候,将会从服务器下载所有邮件
                                可以设置下载完成后,立即/一段时间后删除服务器邮件
                            客户端操作(删除/移动到文件夹)"不会"同步到服务器
                            每个客户端都是独立的,都可以获取自己的电子邮件"副本"
                                A在自己电脑上删除了,服务器不会删,B上还有
                        IMAP
                            客户端连接服务器的时候,获取的是服务器上邮件的基本信息,并不会下载邮件
                                等真正打开邮件的时候,才开始下载邮件  懒加载
                            客户端的操作会同步到服务器
                            所有客户端看到的邮件都是相同的,同步了嘛
            VPN(Virtual Private Network)---虚拟私人网络
                概述
                    可以在公共网络上建立专用网络,进行"加密通讯"
                        原本是用来加密通信的,不是拿来...的
                        默认访问外网,运营商是不会进行加密通信的
                    VPN服务器+VPN客户端
                        装了VPN客户端,先发数据给VPN服务器,然后VPN服务器再访问"目的服务器",像是代理

                        数据先到运营商,运营商再到VPN服务器,这个过程中是加密传输的
                            防止被人劫持,万一运营商被攻击了呢
                        VPN服务器到外网这段不加密

                        数据从客户端到VPN服务器,不管你用的HTTP还是HTTPS,有没有加密,VPN会再加上一层,使用自己的加密方案
                            即便数据被拦截到,它也解析不出来这个加密后的数据,只有客户端和服务器有这个密钥

                        但是从VPN服务器到目的服务器,这段是不加密的,因为他们是HTTP服务器啊,他们哪知道你加密之后的数据是啥,肯定不知道,所以这一段就不加密
                            那如果说诶,我就在VPN到目的服务器,被拦截了,那不还是GG?
                                确实,所以一般VPN服务器--->目的服务器 , 这两都在内网, 而VPN客户端是在外网
                                    比如远程办公,VPN服务器在内网连自己公司的服务器肯定没问题,也不需要加密啥的
                                    但是从外网进来,建立专用网络,这种是要加密的

                        VPN客户端---加密--->ISP---加密--->VPN服务器---不加密--->目的服务器

                        只要数据一从VPN客户端出去,就是已经加密了的
                            VPN软件嘛,负责将数据加密,加密的算法啊都在客户端里,拦截要发送的流量,然后加密
                作用
                    1. 提高上网的安全性
                        防止黑客,ISP,GOV等知道你发的什么数据
                    2. 保护公司内部资料
                    3. 隐藏上网者身份
                        访问目的服务器的,是VPN Server的IP,跟代理差不多
                    4. 突破网站的地域限制
                        有的网站比如Youtube,对不同的地区,展示的内容不一样
                    5. 突破网络封锁
                VPN和代理的区别
                    软件
                        VPN 一般是需要安装对应的VPN客户端软件的
                            因为涉及到加密,不同的VPN有不同的加密方式,只有安装了对应的软件才可以将流量进行对应的加密
                        代理是不需要安装额外的软件
                            直接设置一下就好
                    安全性
                        VPN默认会对数据进行对应加密---安全性好一点
                        代理默认不会对数据进行加密(数据最终是否加密取决于使用的协议本身,比如HTTPS)
                    费用
                        一般情况,VPN比代理贵
                实现原理:
                    使用了隧道协议
                    常见的VPN隧道协议
                        PPTP(Point to Point Tunneling Protocal): 点对点隧道协议
                        L2TP---第二层隧道协议
                        IPsec---互联网安全协议
                        SSL VPN 
                        ...

                        工作在传输层+数据链路层
            网络爬虫/网络蜘蛛
                概述
                    模拟人类使用浏览器操作页面的行为,对页面进行相关的操作
                常用工具
                    python的scrapy框架
                搜索引擎是"严重依赖爬虫"的

                robots.txt 
                    概述
                        是存放在网站根目录下的文本文件
                            eg: www.baidu.com/robots.txt
                        不是一个规范,而只是约定俗称,并不能保证网站隐私
                    作用
                        用来告诉爬虫,哪些内容不应该被爬取,哪些内容是可以被爬取
            无线网络
                蜂窝
                    基站围起来像是蜂窝,所以叫蜂窝网络
            HTTP缓存
                概述
                    接收到服务器响应的数据之后,会把接收到的数据,在缓存中放一份(内存缓存+磁盘缓存)
                        Memory Cache
                        Disk Cache
                    如果下一次请求相同的数据,那么还是从缓存中进行拿

                    Cache-Control: max-age=120
                        缓存的过期时间是120s
                作用
                    某种程度上提高响应速度

                通常会缓存的情况
                    GET请求 + 静态资源(HTML,CSS,JS,IMG...)

                    CTRL+F5: 强制刷新缓存
                        忽略缓存,重新从服务器请求最新的数据
                HTTP缓存机制
                    
                    缓存-响应头
                        Pragma---被淘汰
                            作用类似于Cache-Control,是HTTP/1.0 的产物
                        Expires
                            缓存的过期时间("GMT格式"时间),HTTP/1.0 的产物
                        Cache-Control
                            用来设置缓存策略

                            缓存策略
                                no-storage: 不缓存数据到本地
                                public: 允许"用户","代理服务器"缓存数据到本地
                                    如果中间经过代理服务器,也允许代理服务器可以缓存哦
                                private: 只允许用户缓存数据到本地,"默认" 
                                    不允许代理服务器缓存
                                max-age
                                    缓存的有效时间,单位是s

                                    缓存过期了"不是直接把缓存删掉"啊,而是作为一个标志,然后看看能不能带着ETag和Last-Modified去问服务器
                                no-cache
                                    "每次"需要发请求给服务器"询问缓存是否有变化",再来决定如何使用缓存

                                    就是可以缓存到本地,但是"每次"浏览器在用到这个缓存的时候,都还是需要问服务器,诶这个缓存有没有变化过啊?每次都要问
                                        服务器根据最新的情况,如果没有发生变化,那么就返回304
                                        如果有变化,那么返回最新的数据

                                    适用于更新比较频繁,但是可以使用缓存的数据
                                        比如半个小时啊,一两天之类的
                        Last-Modified
                            资源的最后一次修改时间,GMT格式
                        ETag
                            资源的唯一标识,是个摘要值
                                根据"文件内容"通过"单向散列函数"计算出来的
                                    所以只要文件发生变化,那这个Etag肯定就变,可以用来标识文件是否发生变化
                            所以请求中带有Last-Modified,或者ETag就可以判断文件是否有更新

                        优先级 
                            Pragma>Cache-Control>Expires
                            ETag>Last-Modified
                            
                        304  Not Modified
                            "服务器检测到数据资源没有改变",告诉浏览器直接从缓存拿数据

                            如果设置了max-age,那么在这个有效期内,遇到相同的资源请求,就直接从缓存中拿,如果过期了,那么这个时候才会发请求去问服务器要,这个时候服务器去看资源有没有更新过,如果没有更新,那么就返回304,告诉浏览器资源没变过,你还是直接从缓存中拿吧,如果资源有更新,那么就返回最新的数据

                                比如有一个缓存资源A的max-age=120,那么120s之后,缓存过期了,浏览器发现他过期,就会去问服务器要,然后服务器就会拿着此次请求携带的信息(一般包含对应的资源文件信息)做检查,发现这个资源A根本没有改变过,那就返回浏览器 304 Not Modified,让他直接从缓存中拿,这样就可以很大程度上节省带宽和消耗,如果发现有改变,那么就返回最新的数据
                    缓存-请求头 
                        If-None-Match
                            就是ETag
                            如果上一次的响应头中有ETag,那么就会将ETag的值作为请求头的值
                                如果服务器发现资源的最新摘要值跟If-None-Match不匹配,就会返回最新的资源
                                如果匹配,那么就会返回304
                        If-Modified-Since
                            对应Last-Modified
                            如果上一次响应头中"没有ETag",有Last-Modified,就会将Last-Modified的值作为请求头的值

                                如果服务器发现资源的最后一次修改时间晚于If-Modified-Since,就会返回最新的资源
                                如果一致,返回304
                    Last-Modified 对比 ETage
                        Last-Modified的缺陷
                            只能精确到"秒"级别
                                如果资源在"1s内被多次修改",那么客户端将无法获取最新的资源数据
                            如果文件"内容本质没发生变化",只是中途有修改,那修改时间也发生了变化,那就会重新将资源传给客户端
                                比如我删了一段数据,又加上去了,本质文件还是没发生改变嘛,但是一检测到修改时间发生变化,那么就是最新的资源传过来了,但实质上,文件没发生变化

                                导致相同的数据重复传输,没有使用到缓存
                        ETag可以解决上面两个问题
                            只认内容
                                只要内容没变化,就不会重复传输
                                只要内容有变化,管你1s内变多少次,都可以给到最新的数据给客户端
                    缓存的流程
                        准备发送请求之前,先看本地缓存有没有,如果有,再看响应头中Cache-Control使用的缓存策略,是否为no-cache
                            如果是
                                看看上一次响应头中是否有ETag
                                    如果有,带上上一次的Etag发送一个请求给服务端,比对一下
                                    如果没有,响应头中是否有Last-Modified
                                        如果有,发个请求带上看看文件是否更新...
                                        如果没有,直接请求服务器对应的文件数据...

                            如果不是no-cache
                                就看一下缓存是否过期(max-age)
                                    如果过期,那么就看Etag,再看Last-Modified

                        如果有ETag,那么发送请求时请求头会带上 If-None-Match:xxx 
                        如果没有ETag,而有Last-Modified,请求头会带上 If-Modified-Since
            IPv6 
                概述
                    主要是为了解决IPv4地址枯竭的问题,同时也在IPv4的基础上有许多改进
                    IPv6使用增长缓慢,因为需要设备,操作系统内核升级支持IPv6,毕竟在"网络层"嘛

                    IPv6使用128位地址,而IPv4使用的是32位
                地址格式
                    128bit,每16bit一组,共8组,每组以:隔开,每组以4位16进制方式表示

                    每一组"前面连续的0"可以省略
                        2001:0db8:02de:0000:0000:0000:0000:0e13
                        2001:db8:2de:0:0:0:0:e13
                    可以用双冒号::表示"一组0或多组连续的0",但只能出现一次
                        2001:db8:2de:0:0:0:0:e13
                        2001:db8:2de::e13
                    ::1是本地环回地址(0:0:0:0:0:0:0:1)
                有的服务器支持IPv6,有的不支持,也可以实现IPv4/IPv6共存
            即时通讯(Instant Message,IM)
                概述
                    平常用的QQ,微信都属于IM应用
                    IM云服务
                        网易云信,腾讯云,环信...
                常用的协议
                    XMPP,MQTT,自定义协议

                    XMPP---可扩展消息与存在协议
                        基于TCP,默认端口5222,5269

                        特点
                            使用"XML格式"进行传输,体积较大
                            比较成熟的IM协议,开发者接入方便
                    MQTT(Message Queueing Telemetry Transport)---消息队列遥测传输
                        基于TCP,默认端口1883,8883(带SSL/TLS)

                        特点
                            "开销很小",以降低网络流量,信息冗余远小于XMPP
                            不是专门为IM设计的协议,很多功能需要自己实现,但是很适合IM(信息量很小)
                            很多人认为MQTT是最适合物联网(IoT,Internet of Things)的网络协议
                                用在很小的设备上很合适,比如联网的那些家具

                        发布订阅消息
                            发布者: 客户端
                            代理: 服务器
                            订阅者: 客户端 
            流媒体(Streaming Media)---流式媒体
                概述
                    是指将一连串的多媒体数据压缩后,经过互联网分段发送数据,在互联网上及时传输影音以供观赏的一种技术
                        在线看,在线播放
                        只要拿到分段的那一小块,就可以播放,不一定等到整个视频/音乐下载完之后才能进行播放
                    此技术使得资料数据包得以像流水一样发送,不使用此技术,就必须在使用前下载整个媒体文件
                协议
                    RTP---实时传输协议
                        基于UDP
                    RTCP---实时传输控制协议
                        基于UDP,使用RTP的下一个端口
                        两个结合使用,一个拿来控制,一个拿来传输,有点像FTP
                    RTSP---实时流协议
                        基于TCP,UDP的554端口
                    RTMP---实时消息传输协议
                        默认基于TCP的1935端口
                    HLS 
                        基于HTTP的流媒体网络传输协议

            浏览器发送请求,底层还是要走系统底层的Socket API





                